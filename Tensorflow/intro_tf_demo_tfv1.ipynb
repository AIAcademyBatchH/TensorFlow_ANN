{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zO12Pmc3TjgS"
   },
   "source": [
    "TensorFlow is the dominating Deep Learning framework for Data Scientists and Jupyter Notebook is the go-to tool for Data Scientists. What if you can use TensorFlow from anywhere without the hassle of setting up the environment? Better yet, what if you can use GPU to train your Deep Learning models for free?\n",
    "Google Colaboratory (Colab)is the answer!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Google Colaboratory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fs7Z0Ex4V2yY"
   },
   "source": [
    "Opening up a Colab Notebook\n",
    "When using Colab for the first time, you can launch a new notebook here: colab.reasearch.google.com\n",
    "Once you have a notebook created, it’ll be saved in your Google Drive (Colab Notebooks folder). You can access it by visiting your Google Drive page, then either double-click on the file name, or right-click, and then choose “Open with Colab”.\n",
    "\n",
    "Connecting with GitHub\n",
    "The builders of Colab are so thoughtful that they even baked in the functionality of committing to Github.\n",
    "To connect with GitHub, you first need to create a repo with a master branch on GitHub. Then, from the drop-down menu, select “File —Save a copy in GitHub”. You will be asked to authorize only for the first time. What’s handy is that it even allows you to include an “Open in Colab” button in your notebook on Github like this:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"1.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enabling GPU Support\n",
    "To turn on GPU for your Deep Learning projects, just go to the drop-down menu and select “Runtime — Change runtime type — Hardware accelerator” and choose GPU:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Working with Files\n",
    "You can also upload data to your Colab folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorFlow is an open source machine learning framework for all developers. It is used for implementing machine learning and deep learning applications. To develop and research on fascinating ideas on artificial intelligence, Google team created TensorFlow. TensorFlow is designed in Python programming language, hence it is considered an easy to understand framework."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorFlow is a software library or framework, designed by the Google team to implement machine learning and deep learning concepts in the easiest manner. It combines the computational algebra of optimization techniques for easy calculation of many mathematical expressions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Important features of TensorFlow:\n",
    "\n",
    "It includes a feature of that defines, optimizes and calculates mathematical expressions easily with the help of multi-dimensional arrays called tensors.<br>\n",
    "It includes a programming support of deep neural networks and machine learning techniques.<br>\n",
    "It includes a high scalable feature of computation with various data sets.<br>\n",
    "TensorFlow uses GPU computing, automating management. It also includes a unique feature of optimization of same memory and the data used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why is TensorFlow So Popular?\n",
    "TensorFlow is well-documented and includes plenty of machine learning libraries. It offers a few important functionalities and methods for the same.\n",
    "\n",
    "TensorFlow is also called a “Google” product. It includes a variety of machine learning and deep learning algorithms. TensorFlow can train and run deep neural networks for handwritten digit classification, image recognition, word embedding and creation of various sequence models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mathematical Concepts\n",
    "It is important to understand mathematical concepts needed for TensorFlow before creating the basic application in TensorFlow. Mathematics is considered as the heart of any machine learning algorithm. It is with the help of core concepts of Mathematics, a solution for specific machine learning algorithm is defined."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scalar\n",
    "Scalar can be defined as one-dimensional vector. Scalars are those, which include only magnitude and no direction. With scalars, we are only concerned with the magnitude.\n",
    "\n",
    "Examples of scalar include weight and height parameters of children."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vector\n",
    "An array of numbers, which is either continuous or discrete, is defined as a vector. Machine learning algorithms deal with fixed length vectors for better output generation.\n",
    "\n",
    "Machine learning algorithms deal with multidimensional data so vectors play a crucial role.\n",
    "\n",
    "The pictorial representation of vector model is as shown below −\n",
    "<img src=\"2.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matrix\n",
    "Matrix can be defined as multi-dimensional arrays, which are arranged in the format of rows and columns. The size of matrix is defined by row length and column length. Following figure shows the representation of any specified matrix.\n",
    "<img src=\"3.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mathematical Computations\n",
    "In this section, we will learn about the different Mathematical Computations in TensorFlow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Addition of matrices\n",
    "Addition of two or more matrices is possible if the matrices are of the same dimension. The addition implies addition of each element as per the given position.\n",
    "\n",
    "Consider the following example to understand how addition of matrices works −\n",
    "<img src=\"3.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subtraction of matrices\n",
    "The subtraction of matrices operates in similar fashion like the addition of two matrices. The user can subtract two matrices provided the dimensions are equal.\n",
    "<img src=\"4.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiplication of matrices\n",
    "For two matrices A m*n and B p*q to be multipliable, n should be equal to p. The resulting matrix is −\n",
    "<img src=\"5.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transpose of matrix\n",
    "The transpose of a matrix A, m*n is generally represented by AT (transpose) n*m and is obtained by transposing the column vectors as row vectors.\n",
    "<img src=\"6.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dot product of vectors\n",
    "Any vector of dimension n can be represented as a matrix v = R^n*1.\n",
    "<img src=\"7.png\">\n",
    "The dot product of two vectors is the sum of the product of corresponding components − Components along the same dimension and can be expressed as\n",
    "<img src=\"8.png\">\n",
    "The example of dot product of vectors is mentioned below −\n",
    "\n",
    "\n",
    "<img src=\"9.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensor Data structure\n",
    "\n",
    "Tensors are used as the basic data structures in TensorFlow language. Tensors represent the connecting edges in any flow diagram called the Data Flow Graph. Tensors are defined as multidimensional array or list.\n",
    "\n",
    "Tensors are identified by the following three parameters −\n",
    "\n",
    "#### Rank\n",
    "Unit of dimensionality described within tensor is called rank. It identifies the number of dimensions of the tensor. A rank of a tensor can be described as the order or n-dimensions of a tensor defined.\n",
    "\n",
    "#### Shape\n",
    "The number of rows and columns together define the shape of Tensor.\n",
    "\n",
    "#### Type\n",
    "Type describes the data type assigned to Tensor’s elements.\n",
    "\n",
    "A user needs to consider the following activities for building a Tensor −\n",
    "\n",
    "Build an n-dimensional array\n",
    "Convert the n-dimensional array."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"10.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Various Dimensions of TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### One dimensional Tensor\n",
    "One dimensional tensor is a normal array structure which includes one set of values of the same data type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_1d = np.array([1.3, 1, 4.0, 23.99])\n",
    "print (tensor_1d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Two dimensional Tensors\n",
    "Sequence of arrays are used for creating “two dimensional tensors”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_2d = np.array([(1,2,3,4),(4,5,6,7),(8,9,10,11),(12,13,14,15)])\n",
    "print(tensor_2d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensor Handling and Manipulations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "urp0Oa4UTMIw"
   },
   "source": [
    "Colab has two versions of TensorFlow pre-installed: a 2.x version and a 1.x version. Colab uses TensorFlow 2.x by default, though you can switch to 1.x by the method shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l37YcExiSO7N",
    "outputId": "8e320b1e-7c57-4c8c-870e-edb97244d520"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`%tensorflow_version` only switches the major version: 1.x or 2.x.\n",
      "You set: `1.15.2`. This will be interpreted as: `1.x`.\n",
      "\n",
      "\n",
      "TensorFlow 1.x selected.\n"
     ]
    }
   ],
   "source": [
    "%tensorflow_version 1.15.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Olm69_0qSTDn",
    "outputId": "079ccc6c-1b4c-4f46-832d-135baa8237ec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.15.2\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "8ca5cfMGBv5S"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xZ5mZWagHNgF",
    "outputId": "b3b10977-3b5a-4c43-dbbb-d0b3e9eb907d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: tensorflow\n",
      "Version: 1.15.2\n",
      "Summary: TensorFlow is an open source machine learning framework for everyone.\n",
      "Home-page: https://www.tensorflow.org/\n",
      "Author: Google Inc.\n",
      "Author-email: packages@tensorflow.org\n",
      "License: Apache 2.0\n",
      "Location: /tensorflow-1.15.2/python3.7\n",
      "Requires: wrapt, gast, keras-preprocessing, protobuf, tensorflow-estimator, wheel, grpcio, six, numpy, keras-applications, tensorboard, astor, opt-einsum, google-pasta, absl-py, termcolor\n",
      "Required-by: stable-baselines, magenta, kapre\n"
     ]
    }
   ],
   "source": [
    "# Check TensorFlow versions\n",
    "!pip show tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mAqaMlh0fpcd",
    "outputId": "d42a9f21-5a72-4b51-80be-31cce4c28526"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ML is cool\n"
     ]
    }
   ],
   "source": [
    "# A random cell to be deleted\n",
    "print(\"ML is cool\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jghwVJKjTwNi"
   },
   "source": [
    "Types of Tensors:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "anlrl0tjqjRN"
   },
   "source": [
    "Constant: They are the fixed numbers in your equation. To define a constant, we can do this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "DbcIXRyv8cze"
   },
   "outputs": [],
   "source": [
    "# Define two TensorFlow constants\n",
    "a = tf.constant(1, name='a_var')          \n",
    "b = tf.constant(2, name='b_bar')              "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gp0iM0IIT9w2"
   },
   "source": [
    "Aside from the value 1, we can also provide a name such as “a_var” for the tensor which is separate from the Python variable name “a”. It’s optional but will be helpful in later operations and troubleshooting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VVn8yWcfaRdS",
    "outputId": "06b1a7c9-f74a-4208-ddd0-b996a4a31341"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'a_var:0' shape=() dtype=int32>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# See what the constant a is\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sgg7sFuLUDzZ"
   },
   "source": [
    "Variables: are the model parameters to be optimized, for example, the weights and biases in your neural networks. Similarly, we can also define a variable and show its contents like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "oHRDFr3AlR7c"
   },
   "outputs": [],
   "source": [
    "# Define a variable c\n",
    "c = tf.Variable(a + b)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D0Y86dwwaTyK",
    "outputId": "ba2e47c8-1ad7-4484-fcc5-7d138c486585"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=() dtype=int32_ref>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check out c\n",
    "c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PHSBhhL1UNFS"
   },
   "source": [
    "You might have noticed that the values of a and b, i.e., integers 1 and 2 are not showing up anywhere, why? That’s an important characteristic of TensorFlow — “lazy execution”, meaning things are defined first, but not run. It’s only executed when we tell it to do, which is done through the running of a session! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yCSC-2dZlT6g",
    "outputId": "d65d89d3-d63e-46c1-c59a-0c188c737659"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "# Initialize all variables and run the computational graph\n",
    "# it’s important to note that all variables need to be initialized before use like this:\n",
    "init = tf.global_variables_initializer()      \n",
    "                                                 \n",
    "with tf.Session() as session:                    \n",
    "    session.run(init)                            \n",
    "    print(session.run(c))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ODfXjczEUbcl"
   },
   "source": [
    "Notice that within the session we run both the initialization of variables and the calculation of c. We defined c as the sum of a and b. \n",
    "This, in TensorFlow and Deep Learning speak, is the “computational graph”. Sounds pretty sophisticated, right? But it’s really just an expression of the calculation we want to carry out!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A graph contains tensors and operations. To initiate a graph, a session is created which runs the graph. In other words, graph provides a schema whereas a session processes a graph to compute values( tensors ).\n",
    "tf.Session() initiates a TensorFlow Graph object in which tensors are processed through operations (or ops). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k_peJdbYUolR"
   },
   "source": [
    "Placeholder: Another important tensor type is the placeholder. Its use case is to hold the place for data to be supplied. For example, we defined a computational graph, and we have lots of training data, we can then use placeholders to indicate we’ll feed these in later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GakUyY5vlzsY"
   },
   "source": [
    "#### Placeholder\n",
    "\n",
    "Now let's show the use of placeholder. We'll first use a parabola equation as below:\n",
    "\n",
    "$y = a x^2+bx+c$\n",
    "\n",
    "Here, imagine x, instead of just one number, it's a list of numbers (vector). To calculate the corresponding y value for each x value, we can use placeholder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MTtlAlWKUwW-"
   },
   "source": [
    "Instead of one single x input, we have a vector of x’s. So we can use a placeholder to define x:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "w_Rx6po9bjzU"
   },
   "outputs": [],
   "source": [
    "# Initialize x as a placeholder since we need to feed the data for it\n",
    "x = tf.placeholder(dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nrC9mkutUyoz"
   },
   "source": [
    "We also need the coefficients. Let’s use constants:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "rYzKUwolbj7U"
   },
   "outputs": [],
   "source": [
    "# Initialize the coefficients as constants\n",
    "a = tf.constant(1, dtype=tf.float32)\n",
    "b = tf.constant(-20, dtype=tf.float32)\n",
    "c = tf.constant(-100, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ra27RF_2U7v3"
   },
   "source": [
    "Now let’s make the computational graph and provide the input values for x:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "JPBcHbY0bjnV"
   },
   "outputs": [],
   "source": [
    "# Set up the computational graph\n",
    "y = a * (x ** 2) + b * x + c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "Dl_kL56aQ2ZK"
   },
   "outputs": [],
   "source": [
    "# Provide the feed in data for x\n",
    "x_feed = np.linspace(-10, 30, num=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "_usMBj99Cg0x"
   },
   "outputs": [],
   "source": [
    "# Start and run a session\n",
    "with tf.Session() as sess:\n",
    "  results = sess.run(y, feed_dict={x: x_feed})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7FHFb7KkTikf",
    "outputId": "e55921e0-bb53-4ee1-b447-b33fc61d6c21"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 200.         41.975304  -76.54321  -155.55554  -195.06174  -195.06174\n",
      " -155.55554   -76.54324    41.97534   200.      ]\n"
     ]
    }
   ],
   "source": [
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorboard\n",
    "\n",
    "TensorFlow includes a visualization tool, which is called the TensorBoard. It is used for analyzing Data Flow Graph and also used to understand machine-learning models. The important feature of TensorBoard includes a view of different types of statistics about the parameters and details of any graph in vertical alignment.\n",
    "\n",
    "Deep neural network includes up to 36,000 nodes. TensorBoard helps in collapsing these nodes in high-level blocks and highlighting the identical structures. This allows better analysis of graph focusing on the primary sections of the computation graph. The TensorBoard visualization is said to be very interactive where a user can pan, zoom and expand the nodes to display the details.\n",
    "\n",
    "The following schematic diagram representation shows the complete working of TensorBoard visualization −\n",
    "<img src='11.jpg'>\n",
    "\n",
    "The TensorBoard thus created is useful and is treated equally important for tuning a machine learning model. This visualization tool is designed for the configuration log file with summary information and details that need to be displayed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants creation for TensorBoard visualization \n",
    "a = tf.constant(10,name = \"a\") \n",
    "b = tf.constant(90,name = \"b\") \n",
    "y = tf.Variable(a+b*2,name = 'y') \n",
    "model = tf.global_variables_initializer() #Creation of model \n",
    "\n",
    "with tf.Session() as session: \n",
    "   merged = tf.summary.merge_all()\n",
    "   writer = tf.summary.FileWriter(\"/tmp/tensorflowlogs\",session.graph) \n",
    "   session.run(model) \n",
    "   print(session.run(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir /tmp/tensorflowlogs\n",
    "## hover over the nodes in the graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following table shows the various symbols of TensorBoard visualization used for the node representation −\n",
    "<img src='12.jpg'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## to mount from google drive:\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cGjt7YwTpTYZ"
   },
   "source": [
    "## A Mini Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the basics of TensorFlow, let’s do a mini project to build a linear regression model, aka, a neural network\n",
    "\n",
    "Let’s say we have a bunch of x, y value pairs, and we need to find the best fit line. First, since both x and y have values to be fed in the model, we’ll define them as placeholders:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(dtype=tf.float32, shape=(None, 1))\n",
    "y_true = tf.placeholder(dtype=tf.float32, shape=(None, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of rows is defined as None to have the flexibility of feeding in any number of rows we want.\n",
    "\n",
    "Next, we need to define a model. In this case here, our model has just one layer with one weight and one bias.\n",
    "<img src='15.png'>\n",
    "TensorFlow allows us to define neural network layers very easily:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of units is set to be one since we only have one node in the hidden layer.\n",
    "\n",
    "Furthermore, we need to have a loss function and set up the optimization method. The loss function is basically a way to measure how bad our model is when measured using the training data, so of course, we want it to be minimized. We’ll use the gradient descent algorithm to optimize this loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the loss function\n",
    "loss = tf.losses.mean_squared_error(labels=y_true, \n",
    "                                    predictions=y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.GradientDescentOptimizer(0.01)\n",
    "train = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can initialize all the variables. In this case here, all our variables including weight and bias are part of the layer we defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, we can supply the training data for the placeholders and start the training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_values = np.array([[1], [2], [3], [4]])\n",
    "y_values = np.array([[0], [-1], [-2], [-3]])\n",
    "with tf.Session() as sess:\n",
    "  sess.run(init)\n",
    "  for i in range(1000):\n",
    "    _, loss_value = sess.run((train, loss),\n",
    "                             feed_dict={x: x_values, y_true: y_values})\n",
    "    \n",
    "   # and we can get the weights and make the predictions like so: \n",
    "  weights = sess.run(linear_model.weights)\n",
    "  bias = sess.run(linear_model.bias)\n",
    "  preds = sess.run(y_pred, \n",
    "                 feed_dict={x: x_values})\n",
    "\n",
    "  print(\"The weight is: \", weights)\n",
    "  print('\\r')\n",
    "  print(\"The bias is: \", bias)\n",
    "  print('\\r')\n",
    "  print(\"The predictions are: \\n\", preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "you can verify to confirm the model did make the predictions using its trained weight and bias by:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = weights[0].tolist()[0][0]\n",
    "b = weights[1].tolist()[0]\n",
    "x_values * w + bh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Intro_to_Tensorflow.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
