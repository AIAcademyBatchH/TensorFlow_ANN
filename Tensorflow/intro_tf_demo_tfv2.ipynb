{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1VOEHdMMleUC"
   },
   "source": [
    "# Introduction to Tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wxfLfQu5Zr0C"
   },
   "source": [
    "Tensors are multi-dimensional arrays with a uniform type (called a dtype). You can see all supported dtypes at tf.dtypes.DType.\n",
    "\n",
    "If you're familiar with NumPy, tensors are (kind of) like np.arrays.\n",
    "\n",
    "All tensors are immutable like Python numbers and strings: you can never update the contents of a tensor, only create a new one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "id": "D_0dJGDvJIf9"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oyULJCzfZr3v"
   },
   "source": [
    "### Basic Tensors\n",
    "\n",
    "\"scalar\" or \"rank-0\" tensor . A scalar contains a single value, and no \"axes\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Fkd1ecFjZr7P",
    "outputId": "6fba0393-0cae-45e2-f253-264ad02f5708"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(4, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# This will be an int32 tensor by default; see \"dtypes\" below.\n",
    "rank_0_tensor = tf.constant(4)\n",
    "print(rank_0_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tdmPAn9fWYs5"
   },
   "source": [
    "A \"vector\" or \"rank-1\" tensor is like a list of values. A vector has one axis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oZos8o_R6oE7",
    "outputId": "b0b6ed87-52a3-4501-de9a-c251ade25248"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([2. 3. 4.], shape=(3,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Let's make this a float tensor.\n",
    "rank_1_tensor = tf.constant([2.0, 3.0, 4.0])\n",
    "print(rank_1_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G3IJG-ug_H4u"
   },
   "source": [
    "A \"matrix\" or \"rank-2\" tensor has two axes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cnOIA_xb6u0M",
    "outputId": "60509c34-3682-4ab6-cf22-9c0036abe9ee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[1. 2.]\n",
      " [3. 4.]\n",
      " [5. 6.]], shape=(3, 2), dtype=float16)\n"
     ]
    }
   ],
   "source": [
    "# If you want to be specific, you can set the dtype (see below) at creation time\n",
    "rank_2_tensor = tf.constant([[1, 2],\n",
    "                             [3, 4],\n",
    "                             [5, 6]], dtype=tf.float16)\n",
    "print(rank_2_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "gQznydiZZsJU"
   },
   "outputs": [],
   "source": [
    "##Image in slide 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fjFvzcn4_ehD"
   },
   "source": [
    "Tensors may have more axes; here is a tensor with three axes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sesW7gw6JkXy",
    "outputId": "30a653e7-2712-48be-97b8-40a1e8c2ee91"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[ 0  1  2  3  4]\n",
      "  [ 5  6  7  8  9]]\n",
      "\n",
      " [[10 11 12 13 14]\n",
      "  [15 16 17 18 19]]\n",
      "\n",
      " [[20 21 22 23 24]\n",
      "  [25 26 27 28 29]]], shape=(3, 2, 5), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# There can be an arbitrary number of\n",
    "# axes (sometimes called \"dimensions\")\n",
    "rank_3_tensor = tf.constant([\n",
    "  [[0, 1, 2, 3, 4],\n",
    "   [5, 6, 7, 8, 9]],\n",
    "  [[10, 11, 12, 13, 14],\n",
    "   [15, 16, 17, 18, 19]],\n",
    "  [[20, 21, 22, 23, 24],\n",
    "   [25, 26, 27, 28, 29]],])\n",
    "\n",
    "print(rank_3_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rM2sTGIkoE3S"
   },
   "source": [
    "There are many ways you might visualize a tensor with more than two axes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "1ute3DwagJra"
   },
   "outputs": [],
   "source": [
    "# image in slide 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oWAc0U8OZwNb"
   },
   "source": [
    "You can convert a tensor to a NumPy array either using `np.array` or the `tensor.numpy` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "J5u6_6ZYaS7B",
    "outputId": "a403964b-8a72-45ef-e71b-1842245875d3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 2.],\n",
       "       [3., 4.],\n",
       "       [5., 6.]], dtype=float16)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(rank_2_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c6Taz2gIaZeo",
    "outputId": "04374550-1218-4f26-c611-dab4b68ae550"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 2.],\n",
       "       [3., 4.],\n",
       "       [5., 6.]], dtype=float16)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rank_2_tensor.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hnz19F0ocEKD"
   },
   "source": [
    "Tensors often contain floats and ints, but have many other types, including:\n",
    "\n",
    "* complex numbers\n",
    "* strings\n",
    "\n",
    "The base `tf.Tensor` class requires tensors to be \"rectangular\"---that is, along each axis, every element is the same size.  However, there are specialized types of tensors that can handle different shapes:\n",
    "\n",
    "* Ragged tensors (see [RaggedTensor](#ragged_tensors) below)\n",
    "* Sparse tensors (see [SparseTensor](#sparse_tensors) below)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SDC7OGeAIJr8"
   },
   "source": [
    "You can do basic math on tensors, including addition, element-wise multiplication, and matrix multiplication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-DTkjwDOIIDa",
    "outputId": "b5542c6e-367f-405f-8689-dfc5149389fc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[2 3]\n",
      " [4 5]], shape=(2, 2), dtype=int32) \n",
      "\n",
      "tf.Tensor(\n",
      "[[1 2]\n",
      " [3 4]], shape=(2, 2), dtype=int32) \n",
      "\n",
      "tf.Tensor(\n",
      "[[3 3]\n",
      " [7 7]], shape=(2, 2), dtype=int32) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "a = tf.constant([[1, 2],\n",
    "                 [3, 4]])\n",
    "b = tf.constant([[1, 1],\n",
    "                 [1, 1]]) # Could have also said `tf.ones([2,2])`\n",
    "\n",
    "print(tf.add(a, b), \"\\n\")\n",
    "print(tf.multiply(a, b), \"\\n\")\n",
    "print(tf.matmul(a, b), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2smoWeUz-N2q",
    "outputId": "63da6952-ca3f-406b-bae1-6fc6937fd676"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[2 3]\n",
      " [4 5]], shape=(2, 2), dtype=int32) \n",
      "\n",
      "tf.Tensor(\n",
      "[[1 2]\n",
      " [3 4]], shape=(2, 2), dtype=int32) \n",
      "\n",
      "tf.Tensor(\n",
      "[[3 3]\n",
      " [7 7]], shape=(2, 2), dtype=int32) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(a + b, \"\\n\") # element-wise addition\n",
    "print(a * b, \"\\n\") # element-wise multiplication\n",
    "print(a @ b, \"\\n\") # matrix multiplication"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S3_vIAl2JPVc"
   },
   "source": [
    "Tensors are used in all kinds of operations (ops)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Gp4WUYzGIbnv",
    "outputId": "d615e1d1-a78f-4c0a-e3a5-56dd40c01903"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(10.0, shape=(), dtype=float32)\n",
      "tf.Tensor([1 0], shape=(2,), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[2.6894143e-01 7.3105860e-01]\n",
      " [9.9987662e-01 1.2339458e-04]], shape=(2, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "c = tf.constant([[4.0, 5.0], [10.0, 1.0]])\n",
    "\n",
    "# Find the largest value\n",
    "print(tf.reduce_max(c))\n",
    "# Find the index of the largest value\n",
    "print(tf.argmax(c))\n",
    "# Compute the softmax\n",
    "print(tf.nn.softmax(c)) ##normalized exp fn - in neural networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NvSAbowVVuRr"
   },
   "source": [
    "## About shapes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hkaBIqkTCcGY"
   },
   "source": [
    "Tensors have shapes.  Some vocabulary:\n",
    "\n",
    "* **Shape**: The length (number of elements) of each of the axes of a tensor.\n",
    "* **Rank**: Number of tensor axes.  A scalar has rank 0, a vector has rank 1, a matrix is rank 2.\n",
    "* **Axis** or **Dimension**: A particular dimension of a tensor.\n",
    "* **Size**: The total number of items in the tensor, the product shape vector.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E9L3-kCQq2f6"
   },
   "source": [
    "Note: Although you may see reference to a \"tensor of two dimensions\", a rank-2 tensor does not usually describe a 2D space."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VFOyG2tn8LhW"
   },
   "source": [
    "Tensors and `tf.TensorShape` objects have convenient properties for accessing these:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RyD3yewUKdnK",
    "outputId": "d8394d13-adc2-44d2-9180-76d0a2e8a65e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[[0. 0. 0. 0. 0.]\n",
      "   [0. 0. 0. 0. 0.]\n",
      "   [0. 0. 0. 0. 0.]\n",
      "   [0. 0. 0. 0. 0.]]\n",
      "\n",
      "  [[0. 0. 0. 0. 0.]\n",
      "   [0. 0. 0. 0. 0.]\n",
      "   [0. 0. 0. 0. 0.]\n",
      "   [0. 0. 0. 0. 0.]]]\n",
      "\n",
      "\n",
      " [[[0. 0. 0. 0. 0.]\n",
      "   [0. 0. 0. 0. 0.]\n",
      "   [0. 0. 0. 0. 0.]\n",
      "   [0. 0. 0. 0. 0.]]\n",
      "\n",
      "  [[0. 0. 0. 0. 0.]\n",
      "   [0. 0. 0. 0. 0.]\n",
      "   [0. 0. 0. 0. 0.]\n",
      "   [0. 0. 0. 0. 0.]]]\n",
      "\n",
      "\n",
      " [[[0. 0. 0. 0. 0.]\n",
      "   [0. 0. 0. 0. 0.]\n",
      "   [0. 0. 0. 0. 0.]\n",
      "   [0. 0. 0. 0. 0.]]\n",
      "\n",
      "  [[0. 0. 0. 0. 0.]\n",
      "   [0. 0. 0. 0. 0.]\n",
      "   [0. 0. 0. 0. 0.]\n",
      "   [0. 0. 0. 0. 0.]]]], shape=(3, 2, 4, 5), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "rank_4_tensor = tf.zeros([3, 2, 4, 5])\n",
    "print(rank_4_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "Qg-mP4_jh32Z"
   },
   "outputs": [],
   "source": [
    "# image in slide 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MHm9vSqogsBk",
    "outputId": "1ff806c3-a831-49b6-e91a-28b9f9fb1ed2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of every element: <dtype: 'float32'>\n",
      "Number of axes: 4\n",
      "Shape of tensor: (3, 2, 4, 5)\n",
      "Elements along axis 0 of tensor: 3\n",
      "Elements along the last axis of tensor: 5\n",
      "Total number of elements (3*2*4*5):  120\n"
     ]
    }
   ],
   "source": [
    "print(\"Type of every element:\", rank_4_tensor.dtype)\n",
    "print(\"Number of axes:\", rank_4_tensor.ndim)\n",
    "print(\"Shape of tensor:\", rank_4_tensor.shape)\n",
    "print(\"Elements along axis 0 of tensor:\", rank_4_tensor.shape[0])\n",
    "print(\"Elements along the last axis of tensor:\", rank_4_tensor.shape[-1])\n",
    "print(\"Total number of elements (3*2*4*5): \", tf.size(rank_4_tensor).numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bQmE_Vx5JilS"
   },
   "source": [
    "While axes are often referred to by their indices, you should always keep track of the meaning of each. Often axes are ordered from global to local: The batch axis first, followed by spatial dimensions, and features for each location last. This way feature vectors are contiguous regions of memory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FlPoVvJS75Bb"
   },
   "source": [
    "## Indexing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "apOkCKqCZIZu"
   },
   "source": [
    "### Single-axis indexing\n",
    "\n",
    "TensorFlow follows standard Python indexing rules, similar to [indexing a list or a string in Python](https://docs.python.org/3/tutorial/introduction.html#strings), and the basic rules for NumPy indexing.\n",
    "\n",
    "* indexes start at `0`\n",
    "* negative indices count backwards from the end\n",
    "* colons, `:`, are used for slices: `start:stop:step`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SQ-CrJxLXTIM",
    "outputId": "1acc11c5-60c2-4245-d46a-6c467d28e284"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  1  2  3  5  8 13 21 34]\n"
     ]
    }
   ],
   "source": [
    "rank_1_tensor = tf.constant([0, 1, 1, 2, 3, 5, 8, 13, 21, 34])\n",
    "print(rank_1_tensor.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mQYYL56PXSak"
   },
   "source": [
    "Indexing with a scalar removes the axis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n6tqHciOWMt5",
    "outputId": "969725e8-e6b2-492c-8f0b-9c59c8beef66"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First: 0\n",
      "Second: 1\n",
      "Last: 34\n"
     ]
    }
   ],
   "source": [
    "print(\"First:\", rank_1_tensor[0].numpy())\n",
    "print(\"Second:\", rank_1_tensor[1].numpy())\n",
    "print(\"Last:\", rank_1_tensor[-1].numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qJLHU_a2XwpG"
   },
   "source": [
    "Indexing with a `:` slice keeps the axis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "giVPPcfQX-cu",
    "outputId": "8151ca33-2fd0-421f-f2f5-a0b9717c5291"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Everything: [ 0  1  1  2  3  5  8 13 21 34]\n",
      "Before 4: [0 1 1 2]\n",
      "From 4 to the end: [ 3  5  8 13 21 34]\n",
      "From 2, before 7: [1 2 3 5 8]\n",
      "Every other item: [ 0  1  3  8 21]\n",
      "Reversed: [34 21 13  8  5  3  2  1  1  0]\n"
     ]
    }
   ],
   "source": [
    "print(\"Everything:\", rank_1_tensor[:].numpy())\n",
    "print(\"Before 4:\", rank_1_tensor[:4].numpy())\n",
    "print(\"From 4 to the end:\", rank_1_tensor[4:].numpy())\n",
    "print(\"From 2, before 7:\", rank_1_tensor[2:7].numpy())\n",
    "print(\"Every other item:\", rank_1_tensor[::2].numpy())\n",
    "print(\"Reversed:\", rank_1_tensor[::-1].numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "elDSxXi7X-Bh"
   },
   "source": [
    "### Multi-axis indexing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cgk0uRUYZiai"
   },
   "source": [
    "Higher rank tensors are indexed by passing multiple indices.\n",
    "\n",
    "The exact same rules as in the single-axis case apply to each axis independently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Tc5X_WlsZXmd",
    "outputId": "03d2ff3a-4e10-47c5-f1ec-31cc575c568f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 2.]\n",
      " [3. 4.]\n",
      " [5. 6.]]\n"
     ]
    }
   ],
   "source": [
    "print(rank_2_tensor.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w07U9vq5ipQk"
   },
   "source": [
    "Passing an integer for each index, the result is a scalar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PvILXc1PjqTM",
    "outputId": "07a34486-3012-4d59-fcc8-61593c2c088a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.0\n"
     ]
    }
   ],
   "source": [
    "# Pull out a single value from a 2-rank tensor\n",
    "print(rank_2_tensor[1, 1].numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3RLCzAOHjfEH"
   },
   "source": [
    "You can index using any combination of integers and slices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YTqNqsfJkJP_",
    "outputId": "7ec336c8-686e-4dc1-f4f9-09aabaa2662a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Second row: [3. 4.]\n",
      "Second column: [2. 4. 6.]\n",
      "Last row: [5. 6.]\n",
      "First item in last column: 2.0\n",
      "Skip the first row:\n",
      "[[3. 4.]\n",
      " [5. 6.]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get row and column tensors\n",
    "print(\"Second row:\", rank_2_tensor[1, :].numpy())\n",
    "print(\"Second column:\", rank_2_tensor[:, 1].numpy())\n",
    "print(\"Last row:\", rank_2_tensor[-1, :].numpy())\n",
    "print(\"First item in last column:\", rank_2_tensor[0, -1].numpy())\n",
    "print(\"Skip the first row:\")\n",
    "print(rank_2_tensor[1:, :].numpy(), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P45TwSUVSK6G"
   },
   "source": [
    "Here is an example with a 3-axis tensor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wSC60eEXi86l",
    "outputId": "989e1c3a-926e-48a1-bc1c-6a1575fa4298"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0  1  2  3  4]\n",
      "  [ 5  6  7  8  9]]\n",
      "\n",
      " [[10 11 12 13 14]\n",
      "  [15 16 17 18 19]]\n",
      "\n",
      " [[20 21 22 23 24]\n",
      "  [25 26 27 28 29]]]\n"
     ]
    }
   ],
   "source": [
    "print(rank_3_tensor.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GuLoMoCVSLxK",
    "outputId": "428b79e7-9928-4888-88f1-74c2becd8074"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ 4  9]\n",
      " [14 19]\n",
      " [24 29]], shape=(3, 2), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "print(rank_3_tensor[:, :, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "1MOJkS7ijDb6"
   },
   "outputs": [],
   "source": [
    "# see slide 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t9V83-thHn89"
   },
   "source": [
    "Read the [tensor slicing guide](https://tensorflow.org/guide/tensor_slicing) to learn how you can apply indexing to manipulate individual elements in your tensors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fpr7R0t4SVb0"
   },
   "source": [
    "## Manipulating Shapes\n",
    "\n",
    "Reshaping a tensor is of great utility. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EMeTtga5Wq8j",
    "outputId": "f8b0e468-0692-4c6b-cb9d-2c8cc3253ab0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 1)\n"
     ]
    }
   ],
   "source": [
    "# Shape returns a `TensorShape` object that shows the size along each axis\n",
    "x = tf.constant([[1], [2], [3]])\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "38jc2RXziT3W",
    "outputId": "af31e842-209e-4424-832e-70c7ca288dca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 1]\n"
     ]
    }
   ],
   "source": [
    "# You can convert this object into a Python list, too\n",
    "print(x.shape.as_list())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J_xRlHZMKYnF"
   },
   "source": [
    "You can reshape a tensor into a new shape. The `tf.reshape` operation is fast and cheap as the underlying data does not need to be duplicated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pa9JCgMLWy87",
    "outputId": "31e7f8e5-c09d-4387-9c7a-b3fe64604d09"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[1 2 3]], shape=(1, 3), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# You can reshape a tensor to a new shape.\n",
    "# Note that you're passing in a list\n",
    "reshaped = tf.reshape(x, [1, 3])\n",
    "print(reshaped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Mcq7iXOkW3LK",
    "outputId": "65e20a7b-3226-4868-9533-02dd2466de0c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 1)\n",
      "(1, 3)\n"
     ]
    }
   ],
   "source": [
    "print(x.shape)\n",
    "print(reshaped.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gIB2tOkoVr6E"
   },
   "source": [
    "The data maintains its layout in memory and a new tensor is created, with the requested shape, pointing to the same data. TensorFlow uses C-style \"row-major\" memory ordering, where incrementing the rightmost index corresponds to a single step in memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7kMfM0RpUgI8",
    "outputId": "652d76df-e450-4922-ab6a-c7c4ed371fc4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[ 0  1  2  3  4]\n",
      "  [ 5  6  7  8  9]]\n",
      "\n",
      " [[10 11 12 13 14]\n",
      "  [15 16 17 18 19]]\n",
      "\n",
      " [[20 21 22 23 24]\n",
      "  [25 26 27 28 29]]], shape=(3, 2, 5), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "print(rank_3_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TcDtfQkJWzIx"
   },
   "source": [
    "If you flatten a tensor you can see what order it is laid out in memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "COnHEPuaWDQp",
    "outputId": "5c7780c9-6545-4ed7-9613-56a0efee35bf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29], shape=(30,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# A `-1` passed in the `shape` argument says \"Whatever fits\".\n",
    "print(tf.reshape(rank_3_tensor, [-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jJZRira2W--c"
   },
   "source": [
    "Typically the only reasonable use of `tf.reshape` is to combine or split adjacent axes (or add/remove `1`s).\n",
    "\n",
    "For this 3x2x5 tensor, reshaping to (3x2)x5 or 3x(2x5) are both reasonable things to do, as the slices do not mix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zP2Iqc7zWu_J",
    "outputId": "25f19e23-55ed-4bdb-e047-b6d5881fbdd0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[ 0  1  2  3  4]\n",
      "  [ 5  6  7  8  9]]\n",
      "\n",
      " [[10 11 12 13 14]\n",
      "  [15 16 17 18 19]]\n",
      "\n",
      " [[20 21 22 23 24]\n",
      "  [25 26 27 28 29]]], shape=(3, 2, 5), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[ 0  1  2  3  4]\n",
      " [ 5  6  7  8  9]\n",
      " [10 11 12 13 14]\n",
      " [15 16 17 18 19]\n",
      " [20 21 22 23 24]\n",
      " [25 26 27 28 29]], shape=(6, 5), dtype=int32) \n",
      "\n",
      "tf.Tensor(\n",
      "[[ 0  1  2  3  4  5  6  7  8  9]\n",
      " [10 11 12 13 14 15 16 17 18 19]\n",
      " [20 21 22 23 24 25 26 27 28 29]], shape=(3, 10), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "print(rank_3_tensor)\n",
    "print(tf.reshape(rank_3_tensor, [3*2, 5]), \"\\n\")\n",
    "print(tf.reshape(rank_3_tensor, [3, -1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "3w76ndWijhzT"
   },
   "outputs": [],
   "source": [
    "# see slide 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nOcRxDC3jNIU"
   },
   "source": [
    "(( Reshaping will \"work\" for any new shape with the same total number of elements, but it will not do anything useful if you do not respect the order of the axes.\n",
    "\n",
    "Swapping axes in `tf.reshape` does not work; you need `tf.transpose` for that. ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I9qDL_8u7cBH"
   },
   "outputs": [],
   "source": [
    "# # Bad examples: don't do this\n",
    "\n",
    "# # You can't reorder axes with reshape.\n",
    "# print(tf.reshape(rank_3_tensor, [2, 3, 5]), \"\\n\") \n",
    "\n",
    "# # This is a mess\n",
    "# print(tf.reshape(rank_3_tensor, [5, 6]), \"\\n\")\n",
    "\n",
    "# # This doesn't work at all\n",
    "# try:\n",
    "#   tf.reshape(rank_3_tensor, [7, -1])\n",
    "# except Exception as e:\n",
    "#   print(f\"{type(e).__name__}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J0HG0qk6j_IV"
   },
   "outputs": [],
   "source": [
    "# see slide 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N9r90BvHCbTt"
   },
   "source": [
    "You may run across not-fully-specified shapes. Either the shape contains a `None` (an axis-length is unknown) or the whole shape is `None` (the rank of the tensor is unknown).\n",
    "\n",
    "Except for [tf.RaggedTensor](#ragged_tensors), such shapes will only occur in the context of TensorFlow's symbolic, graph-building  APIs:\n",
    "\n",
    "* [tf.function](function.ipynb) \n",
    "* The [keras functional API](https://www.tensorflow.org/guide/keras/functional).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fDmFtFM7k0R2"
   },
   "source": [
    "## More on `DTypes`\n",
    "\n",
    "To inspect a `tf.Tensor`'s data type use the `Tensor.dtype` property.\n",
    "\n",
    "When creating a `tf.Tensor` from a Python object you may optionally specify the datatype.\n",
    "\n",
    "If you don't, TensorFlow chooses a datatype that can represent your data. TensorFlow converts Python integers to `tf.int32` and Python floating point numbers to `tf.float32`. Otherwise TensorFlow uses the same rules NumPy uses when converting to arrays.\n",
    "\n",
    "You can cast from type to type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5mSTDWbelUvu",
    "outputId": "1b87f1f6-4d83-48d1-96ba-2dfc6a70b306"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([2 3 4], shape=(3,), dtype=uint8)\n"
     ]
    }
   ],
   "source": [
    "the_f64_tensor = tf.constant([2.2, 3.3, 4.4], dtype=tf.float64)\n",
    "the_f16_tensor = tf.cast(the_f64_tensor, dtype=tf.float16)\n",
    "# Now, cast to an uint8 and lose the decimal precision\n",
    "the_u8_tensor = tf.cast(the_f16_tensor, dtype=tf.uint8)\n",
    "print(the_u8_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s1yBlJsVlFSu"
   },
   "source": [
    "## Broadcasting\n",
    "\n",
    "Broadcasting is a concept borrowed from the [equivalent feature in NumPy](https://numpy.org/doc/stable/user/basics.html).  In short, under certain conditions, smaller tensors are \"stretched\" automatically to fit larger tensors when running combined operations on them.\n",
    "\n",
    "The simplest and most common case is when you attempt to multiply or add a tensor to a scalar.  In that case, the scalar is broadcast to be the same shape as the other argument. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P8sypqmagHQN",
    "outputId": "7a69e998-1736-4e3b-c489-5b2b9cdd5dfd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([2 4 6], shape=(3,), dtype=int32)\n",
      "tf.Tensor([2 4 6], shape=(3,), dtype=int32)\n",
      "tf.Tensor([2 4 6], shape=(3,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "x = tf.constant([1, 2, 3])\n",
    "\n",
    "y = tf.constant(2)\n",
    "z = tf.constant([2, 2, 2])\n",
    "# All of these are the same computation\n",
    "print(tf.multiply(x, 2))\n",
    "print(x * y)\n",
    "print(x * z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o0SBoR6voWcb"
   },
   "source": [
    "Likewise, axes with length 1 can be stretched out to match the other arguments.  Both arguments can be stretched in the same computation.\n",
    "\n",
    "In this case a 3x1 matrix is element-wise multiplied by a 1x4 matrix to produce a 3x4 matrix. Note how the leading 1 is optional: The shape of y is `[4]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6sGmkPg3XANr",
    "outputId": "a47eeac3-9c54-430a-c2b7-b9a0b07633b2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[1]\n",
      " [2]\n",
      " [3]], shape=(3, 1), dtype=int32) \n",
      "\n",
      "tf.Tensor([1 2 3 4], shape=(4,), dtype=int32) \n",
      "\n",
      "tf.Tensor(\n",
      "[[ 1  2  3  4]\n",
      " [ 2  4  6  8]\n",
      " [ 3  6  9 12]], shape=(3, 4), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# These are the same computations\n",
    "x = tf.reshape(x,[3,1])\n",
    "y = tf.range(1, 5)\n",
    "print(x, \"\\n\")\n",
    "print(y, \"\\n\")\n",
    "print(tf.multiply(x, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "OeKAjTLfkdPV"
   },
   "outputs": [],
   "source": [
    "# see slide 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9V3KgSJcKDRz"
   },
   "source": [
    "Here is the same operation without broadcasting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "elrF6v63igY8",
    "outputId": "c1fb0944-6cd4-48d5-976c-619ec5d3cf82"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ 1  2  3  4]\n",
      " [ 2  4  6  8]\n",
      " [ 3  6  9 12]], shape=(3, 4), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "x_stretch = tf.constant([[1, 1, 1, 1],\n",
    "                         [2, 2, 2, 2],\n",
    "                         [3, 3, 3, 3]])\n",
    "\n",
    "y_stretch = tf.constant([[1, 2, 3, 4],\n",
    "                         [1, 2, 3, 4],\n",
    "                         [1, 2, 3, 4]])\n",
    "\n",
    "print(x_stretch * y_stretch)  # Again, operator overloading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "14KobqYu85gi"
   },
   "source": [
    "Most of the time, broadcasting is both time and space efficient, as the broadcast operation never materializes the expanded tensors in memory.  \n",
    "\n",
    "You see what broadcasting looks like using `tf.broadcast_to`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GW2Q59_r8hZ6",
    "outputId": "cae59716-5a5c-4bb5-ff84-2bede66c5998"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[1 2 3]\n",
      " [1 2 3]\n",
      " [1 2 3]], shape=(3, 3), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "print(tf.broadcast_to(tf.constant([1, 2, 3]), [3, 3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z2bAMMQY-jpP"
   },
   "source": [
    "Unlike a mathematical op, for example, `broadcast_to` does nothing special to save memory.  Here, you are materializing the tensor.\n",
    "\n",
    "It can get even more complicated.  [This section](https://jakevdp.github.io/PythonDataScienceHandbook/02.05-computation-on-arrays-broadcasting.html) of Jake VanderPlas's book _Python Data Science Handbook_ shows more broadcasting tricks (again in NumPy)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o4Rpz0xAsKSI"
   },
   "source": [
    "## tf.convert_to_tensor\n",
    "\n",
    "Most ops, like `tf.matmul` and `tf.reshape` take arguments of class `tf.Tensor`.  However, you'll notice in the above case, Python objects shaped like tensors are accepted.\n",
    "\n",
    "Most, but not all, ops call `convert_to_tensor` on non-tensor arguments.  There is a registry of conversions, and most object classes like NumPy's `ndarray`, `TensorShape`, Python lists, and `tf.Variable` will all convert automatically.\n",
    "\n",
    "See `tf.register_tensor_conversion_function` for more details, and if you have your own type you'd like to automatically convert to a tensor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iO8Thjqak8Ky"
   },
   "source": [
    "# Variables in Tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AKhB9CMxndDs"
   },
   "source": [
    "A TensorFlow **variable** is the recommended way to represent shared, persistent state your program manipulates. We cover how to create, update, and manage instances of `tf.Variable` in TensorFlow.\n",
    "\n",
    "Variables are created and tracked via the `tf.Variable` class. A `tf.Variable` represents a tensor whose value can be changed by running ops on it.  Specific ops allow you to read and modify the values of this tensor. Higher level libraries like `tf.keras` use `tf.Variable` to store model parameters. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vORGXDarogWm"
   },
   "source": [
    "## Create a variable\n",
    "\n",
    "To create a variable, provide an initial value.  The `tf.Variable` will have the same `dtype` as the initialization value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "dsYXSqleojj7"
   },
   "outputs": [],
   "source": [
    "my_tensor = tf.constant([[1.0, 2.0], [3.0, 4.0]])\n",
    "my_variable = tf.Variable(my_tensor)\n",
    "\n",
    "# Variables can be all kinds of types, just like tensors\n",
    "bool_variable = tf.Variable([False, False, False, True])\n",
    "complex_variable = tf.Variable([5 + 4j, 6 + 1j])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VQHwJ_Itoujf"
   },
   "source": [
    "A variable looks and acts like a tensor, and, in fact, is a data structure backed by a `tf.Tensor`.  Like tensors, they have a `dtype` and a shape, and can be exported to NumPy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GhNfPwCYpvlq",
    "outputId": "fb68d045-2471-4a16-9547-e9e392847fb8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape:  (2, 2)\n",
      "DType:  <dtype: 'float32'>\n",
      "As NumPy:  [[1. 2.]\n",
      " [3. 4.]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape: \", my_variable.shape)\n",
    "print(\"DType: \", my_variable.dtype)\n",
    "print(\"As NumPy: \", my_variable.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eZmSBYViqDoU"
   },
   "source": [
    "Most tensor operations work on variables as expected, although variables cannot be reshaped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TrIaExVNp_LK",
    "outputId": "8d020ada-9498-467c-880c-acb5b38bbcad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A variable: <tf.Variable 'Variable:0' shape=(2, 2) dtype=float32, numpy=\n",
      "array([[1., 2.],\n",
      "       [3., 4.]], dtype=float32)>\n",
      "\n",
      "Viewed as a tensor: tf.Tensor(\n",
      "[[1. 2.]\n",
      " [3. 4.]], shape=(2, 2), dtype=float32)\n",
      "\n",
      "Index of highest value: tf.Tensor([1 1], shape=(2,), dtype=int64)\n",
      "\n",
      "Copying and reshaping:  tf.Tensor([[1. 2. 3. 4.]], shape=(1, 4), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(\"A variable:\", my_variable)\n",
    "print(\"\\nViewed as a tensor:\", tf.convert_to_tensor(my_variable))\n",
    "print(\"\\nIndex of highest value:\", tf.argmax(my_variable))\n",
    "\n",
    "# This creates a new tensor; it does not reshape the variable.\n",
    "print(\"\\nCopying and reshaping: \", tf.reshape(my_variable, [1,4]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qbLCcG6Pc29Y"
   },
   "source": [
    "As noted above, variables are backed by tensors. You can reassign the tensor using `tf.Variable.assign`.  Calling `assign` does not (usually) allocate a new tensor; instead, the existing tensor's memory is reused."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yeEpO309QbB2",
    "outputId": "8a2e3af9-0993-427a-f57f-c311a1837039"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'Variable:0' shape=(2,) dtype=float32, numpy=array([1., 2.], dtype=float32)>\n"
     ]
    }
   ],
   "source": [
    "a = tf.Variable([2.0, 3.0])\n",
    "# This will keep the same dtype, float32\n",
    "a.assign([1, 2]) \n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v6Dqvh5zRTVr",
    "outputId": "af76b287-cdaf-440a-8660-63d42643e1fe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ValueError: Cannot assign to variable Variable:0 due to variable shape (2,) and value shape (3,) are incompatible\n"
     ]
    }
   ],
   "source": [
    "# Not allowed as it resizes the variable: \n",
    "try:\n",
    "  a.assign([1.0, 2.0, 3.0])\n",
    "except Exception as e:\n",
    "  print(f\"{type(e).__name__}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "okeywjLdQ1tY"
   },
   "source": [
    "If you use a variable like a tensor in operations, you will usually operate on the backing tensor.  \n",
    "\n",
    "Creating new variables from existing variables duplicates the backing tensors. Two variables will not share the same memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2CnfGc6ucbXc",
    "outputId": "39d8d9af-18b5-4615-b332-35e0ec27e78b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5. 6.]\n",
      "[2. 3.]\n",
      "[7. 9.]\n",
      "[0. 0.]\n"
     ]
    }
   ],
   "source": [
    "a = tf.Variable([2.0, 3.0])\n",
    "# Create b based on the value of a\n",
    "b = tf.Variable(a)\n",
    "a.assign([5, 6])\n",
    "\n",
    "# a and b are different\n",
    "print(a.numpy())\n",
    "print(b.numpy())\n",
    "\n",
    "# There are other versions of assign\n",
    "print(a.assign_add([2,3]).numpy())  # [7. 9.]\n",
    "print(a.assign_sub([7,9]).numpy())  # [0. 0.]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZtzepotYUe7B"
   },
   "source": [
    "## Lifecycles, naming, and watching\n",
    "\n",
    "In Python-based TensorFlow, `tf.Variable` instance have the same lifecycle as other Python objects. When there are no references to a variable it is automatically deallocated.\n",
    "\n",
    "Variables can also be named which can help you track and debug them.  You can give two variables the same name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VBFbzKj8RaPf",
    "outputId": "9cc82e47-1459-49f2-aae4-f124f0d7ca1d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[False False]\n",
      " [False False]], shape=(2, 2), dtype=bool)\n"
     ]
    }
   ],
   "source": [
    "# Create a and b; they will have the same name but will be backed by\n",
    "# different tensors.\n",
    "a = tf.Variable(my_tensor, name=\"Mark\")\n",
    "# A new variable with the same name, but different value\n",
    "# Note that the scalar add is broadcast\n",
    "b = tf.Variable(my_tensor + 1, name=\"Mark\")\n",
    "\n",
    "# These are elementwise-unequal, despite having the same name\n",
    "print(a == b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "789QikItVA_E"
   },
   "source": [
    "Variable names are preserved when saving and loading models. By default, variables in models will acquire unique variable names automatically, so you don't need to assign them yourself unless you want to.\n",
    "\n",
    "Although variables are important for differentiation, some variables will not need to be differentiated.  You can turn off gradients for a variable by setting `trainable` to false at creation. An example of a variable that would not need gradients is a training step counter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "B5Sj1DqhbZvx"
   },
   "outputs": [],
   "source": [
    "step_counter = tf.Variable(1, trainable=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DD_xfDLDTDNU"
   },
   "source": [
    "## Placing variables and tensors\n",
    "\n",
    "For better performance, TensorFlow will attempt to place tensors and variables on the fastest device compatible with its `dtype`.  This means most variables are placed on a GPU if one is available.\n",
    "\n",
    "However, you can override this.  In this snippet, place a float tensor and a variable on the CPU, even if a GPU is available.  By turning on device placement logging (see [Setup](#scrollTo=xZoJJ4vdvTrD)), you can see where the variable is placed. \n",
    "\n",
    "Note: Although manual placement works, using [distribution strategies](distributed_training) can be a more convenient and scalable way to optimize your computation.\n",
    "\n",
    "If you run this notebook on different backends with and without a GPU you will see different logging.  *Note that logging device placement must be turned on at the start of the session.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2SjpD7wVUSBJ",
    "outputId": "83e6ee20-a765-4032-b022-941dcc655818"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[22. 28.]\n",
      " [49. 64.]], shape=(2, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "with tf.device('CPU:0'):\n",
    "\n",
    "  # Create some tensors\n",
    "  a = tf.Variable([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])\n",
    "  b = tf.constant([[1.0, 2.0], [3.0, 4.0], [5.0, 6.0]])\n",
    "  c = tf.matmul(a, b)\n",
    "\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PXbh-p2BXKcr"
   },
   "source": [
    "It's possible to set the location of a variable or tensor on one device and do the computation on another device.  This will introduce delay, as data needs to be copied between the devices.\n",
    "\n",
    "You might do this, however, if you had multiple GPU workers but only want one copy of the variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dgWHN3QSfNiQ",
    "outputId": "706f7a0b-0bd6-449b-8bb4-4a9f2cf2a901"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ 1.  4.  9.]\n",
      " [ 4. 10. 18.]], shape=(2, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "with tf.device('CPU:0'):\n",
    "  a = tf.Variable([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])\n",
    "  b = tf.Variable([[1.0, 2.0, 3.0]])\n",
    "\n",
    "with tf.device('GPU:0'):\n",
    "  # Element-wise multiply\n",
    "  k = a * b\n",
    "\n",
    "print(k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fksvRaqoYfay"
   },
   "source": [
    "Note: Because `tf.config.set_soft_device_placement` is turned on by default, even if you run this code on a device without a GPU, it will still run.  The multiplication step will happen on the CPU.\n",
    "\n",
    "For more on distributed training, see [our guide](distributed_training)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zvnhIloYk8lW"
   },
   "source": [
    "# Gradients and Automatic Diffrentiation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZZoPm_R9k8o-"
   },
   "source": [
    "Automatic differentiation is useful for implementing machine learning algorithms such as backpropagation for training neural networks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xHxb-dlhMIzW"
   },
   "source": [
    "## Computing gradients\n",
    "\n",
    "To differentiate automatically, TensorFlow needs to remember what operations happen in what order during the *forward* pass.  Then, during the *backward pass*, TensorFlow traverses this list of operations in reverse order to compute gradients."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1CLWJl0QliB0"
   },
   "source": [
    "## Gradient tapes\n",
    "\n",
    "TensorFlow provides the `tf.GradientTape` API for automatic differentiation; that is, computing the gradient of a computation with respect to some inputs, usually `tf.Variable`s.\n",
    "TensorFlow \"records\" relevant operations executed inside the context of a `tf.GradientTape` onto a \"tape\". TensorFlow then uses that tape to compute the gradients of a \"recorded\" computation using [reverse mode differentiation](https://en.wikipedia.org/wiki/Automatic_differentiation).\n",
    "\n",
    "Here is a simple example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "Xq9GgTCP7a4A"
   },
   "outputs": [],
   "source": [
    "x = tf.Variable(3.0)\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "  y = x**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CR9tFAP_7cra"
   },
   "source": [
    "Once you've recorded some operations, use `GradientTape.gradient(target, sources)` to calculate the gradient of some target (often a loss) relative to some source (often the model's variables):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LsvrwF6bHroC",
    "outputId": "882a8b13-175c-4890-816d-413a2e4fa48f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.0"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dy = 2x * dx\n",
    "dy_dx = tape.gradient(y, x)\n",
    "dy_dx.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q2_aqsO25Vx1"
   },
   "source": [
    "The above example uses scalars, but `tf.GradientTape` works as easily on any tensor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "TgguJ8eaxzzg"
   },
   "outputs": [],
   "source": [
    "w = tf.Variable(tf.random.normal((3, 2)), name='w')\n",
    "b = tf.Variable(tf.zeros(2, dtype=tf.float32), name='b')\n",
    "x = [[1., 2., 3.]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8SjXk_BVx1sy",
    "outputId": "a8c8b4a3-709a-4665-b29f-58dad899e396"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'w:0' shape=(3, 2) dtype=float32, numpy=\n",
       "array([[ 0.54971814,  0.40697613],\n",
       "       [ 0.25912225,  0.51409984],\n",
       "       [-1.9965413 ,  0.9840291 ]], dtype=float32)>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MbrqwYcvUGxk",
    "outputId": "7e954cb6-4cc4-4753-910a-45ea27d6c834"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'b:0' shape=(2,) dtype=float32, numpy=array([0., 0.], dtype=float32)>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "vacZ3-Ws5VdV"
   },
   "outputs": [],
   "source": [
    "with tf.GradientTape(persistent=True) as tape: \n",
    "  y = x @ w + b\n",
    "  loss = tf.reduce_mean(y**2)\n",
    "## To compute multiple gradients over the same computation, create a persistent gradient tape. \n",
    "## This allows multiple calls to the gradient() method as resources are released when the tape object is garbage collected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i4eXOkrQ-9Pb"
   },
   "source": [
    "To get the gradient of `loss` with respect to both variables, you can pass both as sources to the `gradient` method. The tape is flexible about how sources are passed and will accept any nested combination of lists or dictionaries and return the gradient structured the same way (see `tf.nest`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "luOtK1Da_BR0"
   },
   "outputs": [],
   "source": [
    "[dl_dw, dl_db] = tape.gradient(loss, [w, b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_syOY5McyIf7",
    "outputId": "0ae5863c-4fa7-4e4f-f673-298e2f485c76"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2), dtype=float32, numpy=\n",
       "array([[ -4.9216614,   4.3872633],\n",
       "       [ -9.843323 ,   8.774527 ],\n",
       "       [-14.764984 ,  13.16179  ]], dtype=float32)>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dl_dw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VElLbDt_yLGF",
    "outputId": "8a7ebe64-afd4-4bf6-f186-407a7d18e9c2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=float32, numpy=array([-4.9216614,  4.3872633], dtype=float32)>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dl_db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ei4iVXi6qgM7"
   },
   "source": [
    "The gradient with respect to each source has the shape of the source:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aYbWRFPZqk4U",
    "outputId": "20cf8c46-84bd-4193-a74e-a39ef4d0d1b7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 2)\n",
      "(3, 2)\n"
     ]
    }
   ],
   "source": [
    "print(w.shape)\n",
    "print(dl_dw.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dI_SzxHsvao1"
   },
   "source": [
    "Here is the gradient calculation again, this time passing a dictionary of variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d73cY6NOuaMd",
    "outputId": "1b0c7eeb-3955-4df5-ac0d-003e750c559d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=float32, numpy=array([-4.9216614,  4.3872633], dtype=float32)>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_vars = {\n",
    "    'w': w,\n",
    "    'b': b\n",
    "}\n",
    "\n",
    "grad = tape.gradient(loss, my_vars)\n",
    "grad['b']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HZ2LvHifEMgO"
   },
   "source": [
    "## Gradients with respect to a model\n",
    "\n",
    "It's common to collect `tf.Variables` into a `tf.Module` or one of its subclasses (`layers.Layer`, `keras.Model`) for [checkpointing](checkpoint.ipynb) and [exporting](saved_model.ipynb).\n",
    "\n",
    "In most cases, you will want to calculate gradients with respect to a model's trainable variables.  Since all subclasses of `tf.Module` aggregate their variables in the `Module.trainable_variables` property, you can calculate these gradients in a few lines of code: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "id": "JvesHtbQESc-"
   },
   "outputs": [],
   "source": [
    "layer = tf.keras.layers.Dense(2, activation='relu')\n",
    "x = tf.constant([[1., 2., 3.]])\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "  # Forward pass\n",
    "  y = layer(x)\n",
    "  loss = tf.reduce_mean(y**2)\n",
    "\n",
    "# Calculate gradients with respect to every trainable variable\n",
    "grad = tape.gradient(loss, layer.trainable_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PR_ezr6UFrpI",
    "outputId": "27c68a30-fb1c-4e4a-cd39-49bbaedc2b89"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dense/kernel:0, shape: (3, 2)\n",
      "dense/bias:0, shape: (2,)\n"
     ]
    }
   ],
   "source": [
    "for var, g in zip(layer.trainable_variables, grad):\n",
    "  print(f'{var.name}, shape: {g.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f6Gx6LS714zR"
   },
   "source": [
    "<a id=\"watches\"></a>\n",
    "\n",
    "## Controlling what the tape watches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N4VlqKFzzGaC"
   },
   "source": [
    "The default behavior is to record all operations after accessing a trainable `tf.Variable`. The reasons for this are:\n",
    "\n",
    "* The tape needs to know which operations to record in the forward pass to calculate the gradients in the backwards pass.\n",
    "* The tape holds references to intermediate outputs, so you don't want to record unnecessary operations.\n",
    "* The most common use case involves calculating the gradient of a loss with respect to all a model's trainable variables.\n",
    "\n",
    "For example, the following fails to calculate a gradient because the `tf.Tensor` is not \"watched\" by default, and the `tf.Variable` is not trainable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Kj9gPckdB37a",
    "outputId": "e68d7044-dafb-4ff0-90d4-38f23d2e761f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(6.0, shape=(), dtype=float32)\n",
      "None\n",
      "None\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# A trainable variable\n",
    "x0 = tf.Variable(3.0, name='x0')\n",
    "# Not trainable\n",
    "x1 = tf.Variable(3.0, name='x1', trainable=False)\n",
    "# Not a Variable: A variable + tensor returns a tensor.\n",
    "x2 = tf.Variable(2.0, name='x2') + 1.0\n",
    "# Not a variable\n",
    "x3 = tf.constant(3.0, name='x3')\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "  y = (x0**2) + (x1**2) + (x2**2)\n",
    "\n",
    "grad = tape.gradient(y, [x0, x1, x2, x3])\n",
    "\n",
    "for g in grad:\n",
    "  print(g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RkcpQnLgNxgi"
   },
   "source": [
    "You can list the variables being watched by the tape using the `GradientTape.watched_variables` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hwNwjW1eAkib",
    "outputId": "0c138a09-bb83-4680-f4b6-bc5130aaedf3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['x0:0']"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[var.name for var in tape.watched_variables()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NB9I1uFvB4tf"
   },
   "source": [
    "`tf.GradientTape` provides hooks that give the user control over what is or is not watched.\n",
    "\n",
    "To record gradients with respect to a `tf.Tensor`, you need to call `GradientTape.watch(x)`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tVN1QqFRDHBK",
    "outputId": "ae27653f-021e-491c-c610-d591aecbe60d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.0\n"
     ]
    }
   ],
   "source": [
    "x = tf.constant(3.0)\n",
    "with tf.GradientTape() as tape:\n",
    "  tape.watch(x)\n",
    "  y = x**2\n",
    "\n",
    "# dy = 2x * dx\n",
    "dy_dx = tape.gradient(y, x)\n",
    "print(dy_dx.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qxsiYnf2DN8K"
   },
   "source": [
    "Conversely, to disable the default behavior of watching all `tf.Variables`, set `watch_accessed_variables=False` when creating the gradient tape. This calculation uses two variables, but only connects the gradient for one of the variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "id": "7QPzwWvSEwIp"
   },
   "outputs": [],
   "source": [
    "x0 = tf.Variable(0.0)\n",
    "x1 = tf.Variable(10.0)\n",
    "\n",
    "with tf.GradientTape(watch_accessed_variables=False) as tape:\n",
    "  tape.watch(x1)\n",
    "  y0 = tf.math.sin(x0)\n",
    "  y1 = tf.nn.softplus(x1)\n",
    "  y = y0 + y1\n",
    "  ys = tf.reduce_sum(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TRduLbE1H2IJ"
   },
   "source": [
    "Since `GradientTape.watch` was not called on `x0`, no gradient is computed with respect to it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e6GM-3evH1Sz",
    "outputId": "a76953c4-bf27-489d-99f5-1fd6ab7b1a91"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dy/dx0: None\n",
      "dy/dx1: 0.9999546\n"
     ]
    }
   ],
   "source": [
    "# dys/dx1 = exp(x1) / (1 + exp(x1)) = sigmoid(x1)\n",
    "grad = tape.gradient(ys, {'x0': x0, 'x1': x1})\n",
    "\n",
    "print('dy/dx0:', grad['x0'])\n",
    "print('dy/dx1:', grad['x1'].numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2g1nKB6P-OnA"
   },
   "source": [
    "## Intermediate results\n",
    "\n",
    "You can also request gradients of the output with respect to intermediate values computed inside the `tf.GradientTape` context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7XaPRAwUyYms",
    "outputId": "aa978d7a-a6e3-4131-9063-848bd6f0518d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18.0\n"
     ]
    }
   ],
   "source": [
    "x = tf.constant(3.0)\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "  tape.watch(x)\n",
    "  y = x * x\n",
    "  z = y * y\n",
    "\n",
    "# Use the tape to compute the gradient of z with respect to the\n",
    "# intermediate value y.\n",
    "# dz_dy = 2 * y and y = x ** 2 = 9\n",
    "print(tape.gradient(z, y).numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ISkXuY7YzIcS"
   },
   "source": [
    "By default, the resources held by a `GradientTape` are released as soon as the `GradientTape.gradient` method is called. To compute multiple gradients over the same computation, create a gradient tape with `persistent=True`. This allows multiple calls to the `gradient` method as resources are released when the tape object is garbage collected. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zZaCm3-9zVCi",
    "outputId": "471115b6-734f-4e5f-8c3d-55b7bb88da6a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  4. 108.]\n",
      "[2. 6.]\n"
     ]
    }
   ],
   "source": [
    "x = tf.constant([1, 3.0])\n",
    "with tf.GradientTape(persistent=True) as tape:\n",
    "  tape.watch(x)\n",
    "  y = x * x\n",
    "  z = y * y\n",
    "\n",
    "print(tape.gradient(z, x).numpy())  # [4.0, 108.0] (4 * x**3 at x = [1.0, 3.0])\n",
    "print(tape.gradient(y, x).numpy())  # [2.0, 6.0] (2 * x at x = [1.0, 3.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "id": "j8bv_jQFg6CN"
   },
   "outputs": [],
   "source": [
    "del tape   # Drop the reference to the tape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O_ZY-9BUB7vX"
   },
   "source": [
    "## Notes on performance\n",
    "\n",
    "* There is a tiny overhead associated with doing operations inside a gradient tape context. For most eager execution this will not be a noticeable cost, but you should still use tape context around the areas only where it is required.\n",
    "\n",
    "* Gradient tapes use memory to store intermediate results, including inputs and outputs, for use during the backwards pass.\n",
    "\n",
    "  For efficiency, some ops (like `ReLU`) don't need to keep their intermediate results and they are pruned during the forward pass. However, if you use `persistent=True` on your tape, *nothing is discarded* and your peak memory usage will be higher."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9dLBpZsJebFq"
   },
   "source": [
    "## Gradients of non-scalar targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7pldU9F5duP2"
   },
   "source": [
    "A gradient is fundamentally an operation on a scalar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qI0sDV_WeXBb",
    "outputId": "e5c5d2bc-286b-4014-b65b-0f2dd654f376"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.0\n",
      "-0.25\n"
     ]
    }
   ],
   "source": [
    "x = tf.Variable(2.0)\n",
    "with tf.GradientTape(persistent=True) as tape:\n",
    "  y0 = x**2\n",
    "  y1 = 1 / x\n",
    "\n",
    "print(tape.gradient(y0, x).numpy())\n",
    "print(tape.gradient(y1, x).numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "COEyYp34fxj4"
   },
   "source": [
    "Thus, if you ask for the gradient of multiple targets, the result for each source is:\n",
    "\n",
    "* The gradient of the sum of the targets, or equivalently\n",
    "* The sum of the gradients of each target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o4a6_YOcfWKS",
    "outputId": "87a1892e-869d-47aa-8718-7cf35567047a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.75\n"
     ]
    }
   ],
   "source": [
    "x = tf.Variable(2.0)\n",
    "with tf.GradientTape() as tape:\n",
    "  y0 = x**2\n",
    "  y1 = 1 / x\n",
    "\n",
    "print(tape.gradient({'y0': y0, 'y1': y1}, x).numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uvP-mkBMgbym"
   },
   "source": [
    "Similarly, if the target(s) are not scalar the gradient of the sum is calculated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DArPWqsSh5un",
    "outputId": "148a24c4-4842-4fc3-c788-f6006a3736a2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.0\n"
     ]
    }
   ],
   "source": [
    "x = tf.Variable(2.)\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "  y = x * [3., 4.]\n",
    "\n",
    "print(tape.gradient(y, x).numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "flDbx68Zh5Lb"
   },
   "source": [
    "This makes it simple to take the gradient of the sum of a collection of losses, or the gradient of the sum of an element-wise loss calculation.\n",
    "\n",
    "If you need a separate gradient for each item, refer to [Jacobians](advanced_autodiff.ipynb#jacobians)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iwFswok8RAly"
   },
   "source": [
    "In some cases you can skip the Jacobian. For an element-wise calculation, the gradient of the sum gives the derivative of each element with respect to its input-element, since each element is independent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "id": "JQvk_jnMmTDS"
   },
   "outputs": [],
   "source": [
    "x = tf.linspace(-10.0, 10.0, 200+1)\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "  tape.watch(x)\n",
    "  y = tf.nn.sigmoid(x)\n",
    "\n",
    "dy_dx = tape.gradient(y, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "id": "e_f2QgDPmcPE",
    "outputId": "4e835ea5-7d62-451c-ff0f-ff697d47fda1"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(x, y, label='y')\n",
    "plt.plot(x, dy_dx, label='dy/dx')\n",
    "plt.legend()\n",
    "_ = plt.xlabel('x')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7PN_2-Sq2P3K"
   },
   "source": [
    "# Basic training loops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pFptkXoR2P3L"
   },
   "source": [
    "TensorFlow also includes the [tf.Keras API](https://www.tensorflow.org/guide/keras/overview), a high-level neural network API that provides useful abstractions to reduce boilerplate.  However, for the moment, we will use basic classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DmQ7Yv6J2P3M"
   },
   "source": [
    "## Solving machine learning problems\n",
    "\n",
    "Solving a machine learning problem usually consists of the following steps:\n",
    "\n",
    " - Obtain training data.\n",
    " - Define the model.\n",
    " - Define a loss function.\n",
    " - Run through the training data, calculating loss from the ideal value\n",
    " - Calculate gradients for that loss and use an *optimizer* to adjust the variables to fit the data.\n",
    " - Evaluate your results.\n",
    "\n",
    "For illustration purposes, in this guide you'll develop a simple linear model, $f(x) = x * W + b$, which has two variables: $W$ (weights) and $b$ (bias).\n",
    "\n",
    "This is the most basic of machine learning problems:  Given $x$ and $y$, try to find the slope and offset of a line via  [simple linear regression](https://en.wikipedia.org/wiki/Linear_regression#Simple_and_multiple_linear_regression)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dc_55x512P3M"
   },
   "source": [
    "## Data\n",
    "\n",
    "Supervised learning uses *inputs* (usually denoted as *x*) and *outputs* (denoted *y*, often called *labels*).  The goal is to learn from paired inputs and outputs so that you can predict the value of an output from an input.\n",
    "\n",
    "Each input of your data, in TensorFlow, is almost always represented by a tensor, and is often a vector. In supervised training, the output (or value you'd like to predict) is also a tensor.\n",
    "\n",
    "Here is some data synthesized by adding Gaussian (Normal) noise to points along a line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "id": "KzQ59WWF2P3N"
   },
   "outputs": [],
   "source": [
    "# The actual line\n",
    "TRUE_W = 3.0\n",
    "TRUE_B = 2.0\n",
    "\n",
    "NUM_EXAMPLES = 1000\n",
    "\n",
    "# A vector of random x values\n",
    "x = tf.random.normal(shape=[NUM_EXAMPLES])\n",
    "\n",
    "# Generate some noise\n",
    "noise = tf.random.normal(shape=[NUM_EXAMPLES])\n",
    "\n",
    "# Calculate y\n",
    "y = x * TRUE_W + TRUE_B + noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 266
    },
    "id": "logISxAF2P3N",
    "outputId": "ed6bb420-524d-4a0c-a03c-9f6b123cb5f2"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot all the data\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.scatter(x, y, c=\"b\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EJVDAiQ92P3P"
   },
   "source": [
    "Tensors are usually gathered together in *batches*, or groups of inputs and outputs stacked together.  Batching can confer some training benefits and works well with accelerators and vectorized computation.  Given how small this dataset is, you can treat the entire dataset as a single batch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lkH5ysCG2P3P"
   },
   "source": [
    "## Define the model\n",
    "\n",
    "Use `tf.Module` to encapsulate the variables and the computation.  You could use any Python object, but this way it can be easily saved.\n",
    "\n",
    "Here, you define both *w* and *b* as variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cyuIAOzw2P3Q",
    "outputId": "14f75f83-fb7c-41d6-ef3a-d6b5888ca1aa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variables: (<tf.Variable 'Variable:0' shape=() dtype=float32, numpy=0.0>, <tf.Variable 'Variable:0' shape=() dtype=float32, numpy=5.0>)\n"
     ]
    }
   ],
   "source": [
    "class MyModel(tf.Module):\n",
    "  def __init__(self, **kwargs):\n",
    "    super().__init__(**kwargs)\n",
    "    # Initialize the weights to `5.0` and the bias to `0.0`\n",
    "    # In practice, these should be randomly initialized\n",
    "    self.w = tf.Variable(5.0)\n",
    "    self.b = tf.Variable(0.0)\n",
    "\n",
    "  def __call__(self, x):\n",
    "    return self.w * x + self.b\n",
    "\n",
    "model = MyModel()\n",
    "\n",
    "# List the variables tf.modules's built-in variable aggregation.\n",
    "print(\"Variables:\", model.variables)\n",
    "\n",
    "# Verify the model works\n",
    "assert model(3.0).numpy() == 15.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "saL-cW562P3Q"
   },
   "source": [
    "The initial variables are set here in a fixed way, but Keras comes with any of a number of [initalizers](https://www.tensorflow.org/api_docs/python/tf/keras/initializers) you could use, with or without the rest of Keras."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AeDUXPQJ2P3R"
   },
   "source": [
    "### Define a loss function\n",
    "\n",
    "A loss function measures how well the output of a model for a given input matches the target output. The goal is to minimize this difference during training. Define the standard L2 loss, also known as the \"mean squared\" error:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "id": "2h44W8te2P3R"
   },
   "outputs": [],
   "source": [
    "# This computes a single loss value for an entire batch\n",
    "def loss(target_y, predicted_y):\n",
    "  return tf.reduce_mean(tf.square(target_y - predicted_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IW67Kohl2P3R"
   },
   "source": [
    "Before training the model, you can visualize the loss value by plotting the model's predictions in red and the training data in blue:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "_jE07-BZ2P3S",
    "outputId": "b6abf70d-5075-4bd3-ca70-d0c848298608"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXkAAAD4CAYAAAAJmJb0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dfYxc53Xf8e/ZIdfiUJZJLRlDpL2zTqAaJV1VgQgVKNrAAWlbEIqoDmDDxK6s2gZoc+1EbRG0bgnUbgoCfUHTqkJEiYWpyJ4bGwFcIUasurLUtE6MuvYqZRSKihrZ4dKiVIukbEUUKVHcPf3jzuXODu+duffOvfNy5/cBBrvz/uyKOvPsec5zHnN3RESkmqaGPQARESmPgryISIUpyIuIVJiCvIhIhSnIi4hU2IZhD6Ddtm3bfG5ubtjDEBEZK0899dQ5d98ed99IBfm5uTmWlpaGPQwRkbFiZstJ9yldIyJSYQryIiIVpiAvIlJhCvIiIhWmIC8iUmEK8iIiwxQEMDcHU1Ph1yAo9OVHqoRSRGSiBAEcOAAXL4bXl5fD6wDz84W8hWbyIiLDcujQWoCPXLwY3l4QBXkRkWE5fTrb7TkUEuTN7JiZvWxmJ9pu+6KZnTGz463LnUW8l4hIZczOZrs9h6Jm8r8D3BFz+39w91tbl8cKei8RkWo4fBjq9fW31evh7QUpJMi7+3eAV4p4LRGRiTE/D0ePQqMBZuHXo0cLW3SF8nPynzOzp1vpnK1xDzCzA2a2ZGZLZ8+eLXk4IiIjZn4eTp2C1dXwa4EBHsoN8keAXwBuBV4C/n3cg9z9qLvvcfc927fHdsoUEZGcSgvy7v4Td19x91XgPwO3l/VeIiISr7Qgb2Y3tV39MHAi6bEiIlKOQna8mtlXgfcD28zsBeALwPvN7FbAgVPAp4t4LxERSa+o6pr97n6Tu29093e5+5fc/W53/xvufou7/4q7v1TEe4mIjISSe84URb1rRESyGkDPmaKorYGISFrR7H1hofSeM0XRTF5EJI3O2XucAnvOFEUzeRGRNOI6RnYqsOdMURTkRUTS6DVLL7jnTFEU5EVE0ug2Sy+h50xRFORFRNollUYmdYxsNkvpOVMUBXkRkUi0uLq8DO5rpZFBUFrHyLLL7c3di33FPuzZs8eXlpaGPQwRmSRBEC6qnj4dRtqVlWsf02iEs/US3rqzYKdez/7ZYWZPufueuPs0kxeRyRQEsG1bWPMezdzjAjyUVho5gCNeFeRFZMIsLkKtFgb38+fTPae16Fp0amUAR7wqyIvIBFlchCNHwgM60mqVRnZL1+c1gCNeFeRFZAJEU/AjR9I9vla7ZnG1jNTKAI54VVsDEam4IIBPfALeeivd4xNWPstIrURvEa37zs6GAb7IakwFeRGpriCAu+8O8ytpzMzAfffFRtnZ2TBFE3d7P+bnyy2xV7pGRKpncTFcHV1YSB/gm004dy4x4g4itVIGBXkRqZZocTVtcJ+aCgN8j+l0SXuhSqd0jYhUQxDAvfemL4uEMFJnSIKXnVopg4K8iIy/aPae1vQ0HDs2fhE7B6VrRGR8RRubsgT4mZmJCfBQUJA3s2Nm9rKZnWi77UYz+7aZ/UXr69Yi3ktEhCAIc+lZNjZdfz00mwT3nWPu0Hzfu1bH5BzvwmbyvwPc0XHb54En3f1m4MnWdRGR/iwuZquaATh4EF57jYD5a3atLiyELWyyBOkydr+WpbAulGY2B/yBu7+vdf054P3u/pKZ3QT8D3d/b7fXUBdKEekqa937xo3w8MNXUzNzc/G17pCt+2PS65TUrLKnYXWhfKe7v9T6/v8B74x7kJkdMLMlM1s6e/ZsicMRkXHSng759W0BF7bNZZvBb958NcBHr5UU4CFsUXDPPelm44NoLFaUgVTXuLubWex/GXc/ChyFcCY/iPGIyGhr77N+nN3ccv4klvbJmzfDQw9dnZLH9WxPsrISPha6z+jL2v1ahjJn8j9ppWlofX25xPcSkQo5dAjuuhhwkU3cQroA7wA7dsCFC+sidFxjsW7SNB0bp92vZQb5bwD3tL6/B/j9Et9LRKpi507+ctkIWGATb/QM8N66/NH0XjhzZt19QdA9RZOkV9plnHa/FlVC+VXgfwHvNbMXzOxTwL8GPmBmfwHsa10XEUlWr8OLL2KQKrifosE8Ta6vOz8+9sTV+9oPfcojTdplfj5cZF1dHelzvIvJybv7/oS79hbx+iJSPe1Hq87Ownc372PnpUupnuvAvTNN7j8/T60GKx0plrQ5+DjT02HGZ2qqnNa/g6YdryLSt24bg+Lua68z/0++yA+Xa+w4+WTq97Ndu/hb981Tr68dyxrVqt97b7YAPz0dboI1C7+6h+1vRr3+Pa3C6uSLoDp5kfETV70S1ZxD/H3zFnD/6/cwTRihUy+sAi/u2svOZ57oWRKZRmd/slGrf0+rW528GpSJSF96HYvXed9dFwMeZCF1GsGBKxj38BW+yjz1U3A0KKcmfZzq39PSTF5E+jI1Fb8/yVrT8877XuV6buD1VK/twGts4h2s/6RoNMK8eVxX4ZkZuHQpfcqmfadrFWfyysmLSF+SKlFmZ9fuO85uVjFWMd6eIcA/zt5rAjyEgTipbfxHP3pteePBg+HXOO1/dYxT/XtaCvIi0pc771ybtUc2bgxn2g8t72MVu7qhKW1p5F+xmXma3METPR59rcceu7a88YEHwq+d44xE6Zhxqn9PS0FeRHpKqp4JAnjkkWtTMu7w5PndfJAnUwX2q88jmr1f4Kvki6zLy8nVMN3+6oiMS/17Wlp4FZGuOqtnorJCSG4Z8PyVnczyYqbgvgJ8nGbu4N4uqf/M4cPx1T7jnI7pRTN5EemqW/VMZ9XJtwjTM2kDfFg5U+O3OchGvJAA3z6+TlVMx/SiIC8ywaI0jFl4ip7Z+u+71aIvL6+lOe5nkRUsU3rGoRXcr/BrPFDIz9M5vrjNWVVLx/SiIC8yoRYXw/M3oiDefope9H23zUa1GjTvDHgL47McYYpsufen2ZU7uEcLqLVaj/epyK7VfijIi0yYqHnXkSPZTtDr9NGVgL99ZIENZAvuq4Qz+Ft5Jv+bE479yhVoNsNqnm7StA+uKgV5kQkSBOHpR0k15mndzyJBjl2r8zSp4X2nZzqrYW64ofdzxnnXaj9UXSMyQT796bWGXnl8i318kLCRWJbZ+zm28HP8tOdjN2wIZ+fdxFXDvPJK73GM4qlNg6CZvMgY6dbtMc39r6fbbHqNqGomb917mgAP8I53xN8eLQQnVcP0CuBVL5Psyt1H5nLbbbe5iMRrNt3rdfcwGx1e6vXw9uj+6en1909Pr7+//b60l1Ps8NWMT1oFf5XNvp9m6qc1Gu5m8feZ9f7ddP7s0WVmZu13UFXAkifE1aEH9vaLgrxIskaje4C8/vruQXRqKltw30/TV1oBO0twX4FMwb39wyrpZ2w0ev9+ms0woE9ScI90C/LKyYuMiW4Lh2n6qreXSPZyimw7ViFb7r1dZ0/3vDtS5+erX/Oeh3LyImNiEAuHWXeswvqyyDwBvn1DUpYdqb3WHySkIC8yIFmDUufj77zz2ja4RXqd6VwLq6fZkasscuPG+Bl6mh2p7ccHujY8dZeUxxnGRTl5qapei6btj+uWewf3Wi1bbr3X5X4O+mqO3Ptqjtx7+6WffHk/ufsqoktOvvSToczsFPAaYZO5K55wegnoZCiprjQnDsWdlVq2y1imHauQP/fert+TlrqdRpVl7aEqRuFkqF9291u7BXiRqgqC5IXR9sXUpLa9ZYhy71lbEqwA8zT7CvDQf816mr7wElJOXqRA7Xn0bdvg+uthYSH58e1BaRDb7vcT5OoWuUoY3DcU0A74+uv7r4Kp4jF9ZRlECaUDj5uZAw+5+9H2O83sAHAAYFYfwzLGOtMtvfrDdAal2dl0pZB5vcxWtvGzzKmZ0+xgjjOFjSPvrtt20YdE1NN+dnZ9GaasGUROfqe7nzGznwO+Dfyau38n7rHKycs469Z7Pc7Bg+F5pKdPw403whtvFBMAO+0noMlCpqoZ4Gq/96J7vfebj5drDTUn7+5nWl9fBh4Fbi/7PUX6kbf+Oku6ZfPmsNVvVAJ4/nw5Af5ltl7tFpkl936FMD1TdIBXSmXwSg3yZrbZzN4efQ98EDhR5nuK9KOf+uss2cYyAnq7+1lkFcuUnvHW5XH2FnoUX6RWq/5Re6Oo7Jn8O4E/NrM/Bb4PfNPdv1Xye4rklnSe6cLC+ll9dPBGdFzetm3lb1ZK63Wm+SxHMm9quswUUzh38EQp41pdVYAfhlKDvLv/yN3/Zuuy2931h5qMtF79YQ4cCI/N+/jH1y+snj8PX/pSeCDHsERlkZt4K/Ps/Wl2cR19NJpPQXUVw6ESSpE2vQLRxYvw0EPxG24uXw7TEcPwKvVcLQkcmMJTHcU3MxMetefe+2zVTsrFD4+CvEy0uP4w09Pdn9NtR2U/py7lEc3e386lXLP3GsnVdZs3r/9dnD+/tj5x4EDy65vB3r3pmoxJ+dRqWCZGEKyvq77zTnjkkbUc/PJyeH3jxnBWPurytiR4jU28g+5ba2dmwk1LnSWh0YHYUQnk0aPrP9g62wbL8JVeJ5+F6uSlLHF9Yczi+5+Muv0EBITbaLPM3iEsi+xVNVOvh8H77rvVH2ZcdKuT10xeJkJc1cw4Bvi8u1bTzN4hDOD33BPOxA8dit/cpQXU8aKcvFRWe769zHYBgxDl3rPWvUeHeaQJ8BB+8D32WPi9+sNUg2byUknDaNtbljeoMc1q5tTM0+xKVTXTKSojVX+YalBOXiopSx+ZUc3NH2c3t3ASyF4W2a1qphf1lhk/ysnLxMnSR2YUA/wVLFO/GciWe0+idEz1KCcvldBZ737jjcMeUT4vs5XVjAG+vd97Z4A3C38nSaanw3JJ1bNXl4K8jKy03SDjmoq99lpY7z4uOhuKpT3Mo31TU1xp5OwsfPnLaxuTZmbWB/Vjx+Dcue6HZst4U05eRlLcwmlUv90ZiJLy70kbekbN60xn6jcDYXC/xEY2033XlmraJ8MonPEqkklSN8hDh659bFL+/ZVXwtlpsxlu0R810ew9a0OxKDXTK8CDatpFC68yopICd9ztScfmzc7Cvn3w5JPFjq0IeWfvV4DplJUzWkQV0Exehqhbzj1pBhp3e9Kmnc2bRy/A99sOuFeAjxZZtYgqEc3kZSg6c+5Rr3YIA9Phw/E5+c6ZadR07OLFsP3tykqYh79wAU6eHMzPktYKluuc1bjZe/SzRl/VGEySKMjLUCTl3KNDN9Lstuz8oIi6IV64UO7Ys4pSM5C9odjj7I09qWl1dTTr+2X0KMjLUCTl3FdWwsD93e+GPVS6baeP+6AYJfezyGc5AmSfva8CG7qkZrSgKmkpJy9D0S1IXbwIDz7Y+zDtLLtaB+0NarnOWY0O0m4P8NbxAt0WVNPuLZDJoSAvhUsTaOIWS9t1piKiw7S3bVs7QHtU0xUrWOaGYlFLgs6DtOt1+Mxn0p2yFLcpLO7DUSaMu5d6Ae4AngOeBz7f7bG33Xaby3hrNt3rdfcwzISXej28Pe6xtdr6x47zZT9NXwFfzfCkVfC3wMG90XA/eDD8ahZ+jfu9JWk04t+m0SjkP62MMGDJE+JqqTl5M6sBvw18AHgB+IGZfcPdR6zuQYqSdkE1ct118PrrgxlbWfrJvZ9mB3OcKaTzY5a9BTI5yk7X3A487+4/cvfLwNeAu0p+TxmibguqCwuwuBhej1IL4x7gL2O5cu9XCHetznEGKCYQZ9lbIJOj7CC/E/hx2/UXWrddZWYHzGzJzJbOnj1b8nCkbL26Px45EuaWFxZGuzKml2hTU5aDtNs3NW3saChWRCDWSU4SZ+gllO5+FDgKYYOyIQ9H+hAEYffHqst6UhN0b0lQVCDWSU4Sp+yZ/Bng3W3X39W6TSro0CG43Ltn1tg6zm5Wc1bOnGYH0zj1Ohw8mK5aJo/5+TC3r9bBEik7yP8AuNnM3mNm08DHgG+U/J5SsqQSySov8F3GuIWTuerep/Cri6tHj8IDDygQy+CUmq5x9ytm9jngvwE14Ji7Zz9ZWEZGt54zN94I588Pb2xl+Bb7+CBhl7OsLQmiypmkPvgig6BDQySTbgd0vPoqXLky8CGVJk9DMQhbEvx8w5UXl4HRQd5SmKSUTJVm8MfZzS2EWzmyBniaTabm5zlV9KBEclKQl9SCIMzDR90eq2Y/AQELQI7gvmMHnFFNgYweBXlJJcrFxwX4DRvGP03zMluvHqKdWbOpfIyMLAV5SaVbW99xDvD7CWiykCv3DoxulzSRFgV5SSVusXXcnWIns7yo4C6VplbDclVU/24WpmDav1aFGTyzYx+O0cgT4HftUoCXsaIgP2GSNjK19yKHtdx7FRZZp6bWdpe+saHOrhdznu7tDs9om4eMF6VrKi466Pr06XCz0muvrbUeaN/INOpH6eW1biNS3j9JtmyBn/600HGJDIqCfIV17k6Nq2WPTlyqopkZuO8+mP/ENCy8lf0FqlwvKhND6ZqKCoLwoI4qzs7TOnfrPuYXDN7KEeCbTQV4qQTN5CuoW037OCji/NY3qcGTq/merIVVqRDN5Cto3PPrG/qceqxgbCRHgN+0SQFeKkdBvoLGueVvrdY7u1KrhV8711FPsZPVjE3FHNaC+zh/MookUJCvoF5H8CWJguew1OvpUkyrq2FM/spXwrLIV6mzil3d2JQmwEe93r/NXgV3qTQFeQHCAD+MHP5U619gdKBGo9H7OdF5qPMEnFo2buBSroO0p3AONJ7IPmiRMaIgPwKSNijl9cor2Z8zqABfq61tTIoKWNzXTkiKO4y63dXzUBcXM9d+th+kHR3Fp0OupfLcfWQut912m0+aZtO9XncPQ114qdfD27O+TqPhbhZe2l9vlC5m68faaFz7s7bfPzMTXqLHPrv3YO43v7RpS9f3FRlXwJInxFWdDDVkSSctNRrh7DaNzk1Po2xmBi5dWj/W1Mfjbd0KP/tZvjceoX/nIkXrdjKU0jVDllQJk6VCZhRLJqenYePG9bdFaZjOsV68GP4MiRYXwxxPngC/Y4cCvEw0BfkhixYR094eZ9RKJhsNOHYMHn44/D7KwR89mrxekPgzmMGRI/kG4q7TmmTilRbkzeyLZnbGzI63LneW9V7jLG6hsX1BMM2ibJYPhDymUv4rqdfDxdRoEXV+Pvx+dXXtttQfakGQv6HY3r2avYtEkpL1/V6ALwK/keU5k7jw6p68EJlmUbbZDBcmh72YmnYhM9VC85Yt+QaycWNx/1FExghdFl6VrsmoiHLHzteAa2e8EJ9rb89fRwuucd0li9RohAumSfd1jrub+fm1evj2NM7V5+bNvR88uNZDWUTWJEX/fi+EM/lTwNPAMWBrwuMOAEvA0uzsbOmfeP0ootwxy2t0K4U0c6/VBjNLbzaLK/Xs+ovJM8C9ewsagMj4ostMvt9A/gRwIuZyF/BOoEaY9z8MHOv1eqOermk04uNMo1Hsa0Tpm2GmYNovneMqtM78YM66d6VmRK7qFuQHUidvZnPAH7j7+7o9btTr5KemwgjTySxMWaTRbS3RvZia97QtCqan4VOfgsceSz6oO0u9fmb1elg0n5UO8xBZZyh18mZ2U9vVDxPO8MdaEeWOSU3Aotv7rXlP0+QryoUfOwYPPBAG8Waze5VPoaK69zwBfu9eBXiRDMpceP23ZvZnZvY08MvAPyrxvQaiV7ljGknxKbo9qV48Csxx2vvB9GrylbRQ2nNBtCj1er669127wj91nlBDMZFMkvI4w7iMek7evf+8dK+cfLf70y5+NpthyjrudWZmhtSzZdeufLn3TZuGMFiR8UJZC69FX8YhyPerV6COuz+qsmk0wnXKNB8y3ernC62KSWPTpuzBfceOAQ5QZLwpyI+YtF0Y2wN83gBdREVQbnln71u2DGBwItXRLchrM9QApN38FInaATQa11bz9Gzm1aGIBmi5bN0KJ09mf97Bg/DTnxY/HpEJ1eeRydJLZ0nk8nJ4HXovahYRoGdn48sjS+t3s3t3vuC+Y4eaiYmUQDP5kvVqTdBNESWbRVQEpRI1FMs7e1eAFymFgnwf0vSx6Wc2XkSAHkhp5L59mY/iA8KG8+5hsb6IlEJBPqcoDbO8HMapKA3TGej7mY0XFaDjWv4WIgjCT7gnn8z+XDUUExkIHf+XU9KxfbUaPPLIWiCNa1OQ+ri7Uba4mG9T06ZNo3eMlciY0/F/JUhKt6ysrJ/R95qNF9G6eKCCADZsyBfgd+xQgBcZMM3kc0qayUfSNPYau1n+vn35UjOavYuUSjP5EsQtirZLs7DaT+XNwO3cmT/3rgAvMjSqk88pmmnfc09807E0C6tD26iU1e7d8OKL2Z6zd6+aiYmMAM3k+zA/Hy6y5i1zLKIOvjRBANu25at9bzYV4EVGhGbyfWo/j/X06TBAHz6cLqd++HB8Tr6UHu5ZbN2a75xV7VoVGTmayRcgbx36wHq4pxXtWs0a4PfuDTcLKMCLjBzN5Idsfn4EKmmCAO69F86fz/Y8zdxFRp5m8pNucRHuvjt7gN+1SwFeZAwoyE+qIAjr148ciT+dPMnMTLiw+swz5Y1NRAqjdM0kCoJw9p4luJvBV74yArklEclCQX6SBAF86lPw5pvZnjc1lXwCuYiMtEqka8au/8swLC6G7YCzBvgtWxTgRcZYX0HezD5iZs+Y2aqZ7em475+Z2fNm9pyZfai/YSZL2/J3YkXtgLM2FKvVdBSfSAX0O5M/Afwq8J32G81sF/AxYDdwB/CAmdX6fK9YY9X/ZdCi2XuW3PvUVLiweuWKDvMQqYC+gry7P+vuz8XcdRfwNXd/093/EngeuL2f90oyNv1fBilvO+C3vQ2+/GUtropUSFk5+Z3Aj9uuv9C67RpmdsDMlsxs6ezZs5nfaKT7vwxDNHvPkke/7rpw9v7GGwrwIhXTM8ib2RNmdiLmclcRA3D3o+6+x933bN++PfPzB3ZQ9TgIAnjwwWzP2bULLl1ScBepqJ4llO6+L8frngHe3Xb9Xa3bCtdPg7BKCYKw73Ha/Lvq3kUmQll18t8AftfMfgvYAdwMfL+k9xqN/i/DkqfvzK5d2rEqMiH6CvJm9mHgfmA78E0zO+7uH3L3Z8zs94CTwBXgs+6uYuuixZ0f2I0aiolMnL6CvLs/CjyacN9hYBIz4+UKgrXcVJadqJq9i0ykSux4nRidO796BfhaLayacVeAF5lQCvLjJG7nV5J6PTybcGIXK0QEFORH3+JiuLHJLJzBpzEzM+QjpkRkVCjIj7LFxXDXapq0THR+YLMJ584pwIsIoFbDoylaXE0zc6/XNWsXkUQK8qMmbVmk2QTv/BKRtBTkR02axdVaLewSKSLSg3LywxYEsG1bODNPu7h64ED54xKRStBMfpiCAD75Sbh8Od3ja7UwwKvPu4ikpCA/DIuL4WJp2t2qWlwVkZyUrhm0tGWRsFYWqQAvIjlpJj8I7f1m0rYCbjTg1KlShyUi1acgX7asnSIBNm6c0FNPRKRoSteULUu/GQhbEjz8sNIzIlIIzeTLlvZE8YMHVTUjIoXTTL5svU4Ur9UU4EWkNAryZUs6aTzq837ligK8iJRGQb4IQQBzc+FJTXNz4fXI/HxYAtloqCRSRAZOOfl+xB2ivby81nYgCuQTfdK4iAyTZvJ5RaWR7QE+cvFiWFUjIjJkfQV5M/uImT1jZqtmtqft9jkzu2Rmx1uXB/sf6oiIUjMLC91LI9NW1YiIlKjfdM0J4FeBh2Lu+6G739rn64+WLBubelXViIgMQF9B3t2fBTCzYkYz6tJubKrXtWNVREZCmTn595jZ/zGz/2lmfzfpQWZ2wMyWzGzp7NmzJQ6nAGlSMDpEW0RGSM8gb2ZPmNmJmMtdXZ72EjDr7r8I/GPgd83shrgHuvtRd9/j7nu2b9+e76cYlG4pGB2iLSIjqGe6xt33ZX1Rd38TeLP1/VNm9kPgrwFLmUc4Sg4fvjYnr17vIjLCSknXmNl2M6u1vv954GbgR2W810BpY5OIjJm+Fl7N7MPA/cB24JtmdtzdPwT8EvCbZvYWsAp8xt1f6Xu0o0Abm0RkjPRbXfMo8GjM7V8Hvt7Pa4uISP+041VEpMIU5EVEKkxBXkSkwhTkRUQqTEFeRKTCFORFRCpMQV5EpMIU5EVEKkxBXkSkwqoR5LsdpC0iMsHG/yDvztOa4g7SFhGZUOM/k487rUkHaYuIAFUI8kmnNekgbRGRCgT5pNOadJC2iEgFgvzhw+HpTO10kLaICFCFIK/TmkREEo1/dQ3otCYRkQTjP5MXEZFECvIiIhWmIC8iUmEK8iIiFaYgLyJSYebuwx7DVWZ2Flge9jhS2gacG/YgMtKYB2ccx60xD0YZY264+/a4O0YqyI8TM1ty9z3DHkcWGvPgjOO4NebBGPSYla4REakwBXkRkQpTkM/v6LAHkIPGPDjjOG6NeTAGOmbl5EVEKkwzeRGRClOQFxGpMAX5PpjZvzKzp83suJk9bmY7hj2mXszs35nZn7fG/aiZbRn2mHoxs4+Y2TNmtmpmI10uZ2Z3mNlzZva8mX1+2ONJw8yOmdnLZnZi2GNJw8zebWZ/aGYnW/8u7h32mNIws+vM7Ptm9qetcf/LgbyvcvL5mdkN7v5Xre9/Hdjl7p8Z8rC6MrMPAv/d3a+Y2b8BcPd/OuRhdWVmfx1YBR4CfsPdl4Y8pFhmVgP+L/AB4AXgB8B+dz851IH1YGa/BFwAvuzu7xv2eHoxs5uAm9z9T8zs7cBTwN8fg9+zAZvd/YKZbQT+GLjX3b9X5vtqJt+HKMC3bAZG/hPT3R939yutq98D3jXM8aTh7s+6+3PDHkcKtwPPu/uP3P0y8DXgriGPqSd3/w7wyrDHkZa7v+Tuf9L6/jXgWWDncEfVm4cutK5ubF1KjxkK8n0ys8Nm9mNgHvgXwx5PRp8E/uuwB1EhO4Eft11/gTEIPuPMzOaAXwT+93BHko6Z1czsOPAy8G13L33cCvI9mNkTZnYi5nIXgLsfcvd3A9p0F6MAAAFvSURBVAHwueGONtRrzK3HHAKuEI576NKMWaSdmV0PfB34hx1/VY8sd19x91sJ/4K+3cxKT49V4/i/Ern7vpQPDYDHgC+UOJxUeo3ZzP4B8PeAvT4iizIZfs+j7Azw7rbr72rdJgVr5bS/DgTu/l+GPZ6s3P1nZvaHwB1AqQvemsn3wcxubrt6F/DnwxpLWmZ2B/BPgF9x94vDHk/F/AC42czeY2bTwMeAbwx5TJXTWsD8EvCsu//WsMeTlpltj6rZzGwT4QJ96TFD1TV9MLOvA+8lrPxYBj7j7iM9czOz54G3AedbN31vDCqCPgzcD2wHfgYcd/cPDXdU8czsTuA/AjXgmLsfHvKQejKzrwLvJ2yB+xPgC+7+paEOqgsz+zvAHwF/Rvj/HsA/d/fHhjeq3szsFuARwn8bU8Dvuftvlv6+CvIiItWldI2ISIUpyIuIVJiCvIhIhSnIi4hUmIK8iEiFKciLiFSYgryISIX9fz/23tHqxS7MAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current loss: 9.300709\n"
     ]
    }
   ],
   "source": [
    "plt.scatter(x, y, c=\"b\")\n",
    "plt.scatter(x, model(x), c=\"r\")\n",
    "plt.show()\n",
    "\n",
    "print(\"Current loss: %1.6f\" % loss(y, model(x)).numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S_v0jp_v2P3S"
   },
   "source": [
    "### Define a training loop\n",
    "\n",
    "The training loop consists of repeatedly doing three tasks in order:\n",
    "\n",
    "* Sending a batch of inputs through the model to generate outputs\n",
    "* Calculating the loss by comparing the outputs to the output (or label)\n",
    "* Using gradient tape to find the gradients\n",
    "* Optimizing the variables with those gradients\n",
    "\n",
    "For this example, you can train the model using [gradient descent](https://en.wikipedia.org/wiki/Gradient_descent).\n",
    "\n",
    "There are many variants of the gradient descent scheme that are captured in `tf.keras.optimizers`. But in the spirit of building from first principles, here you will implement the basic math yourself with the help of `tf.GradientTape` for automatic differentiation and `tf.assign_sub` for decrementing a value (which combines `tf.assign` and `tf.sub`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "id": "hVUMo19D2P3T"
   },
   "outputs": [],
   "source": [
    "# Given a callable model, inputs, outputs, and a learning rate...\n",
    "def train(model, x, y, learning_rate):\n",
    "\n",
    "  with tf.GradientTape() as t:\n",
    "    # Trainable variables are automatically tracked by GradientTape\n",
    "    current_loss = loss(y, model(x))\n",
    "\n",
    "  # Use GradientTape to calculate the gradients with respect to W and b\n",
    "  dw, db = t.gradient(current_loss, [model.w, model.b])\n",
    "\n",
    "  # Subtract the gradient scaled by the learning rate\n",
    "  model.w.assign_sub(learning_rate * dw)\n",
    "  model.b.assign_sub(learning_rate * db)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6VktO8KK2P3T"
   },
   "source": [
    "For a look at training, you can send the same batch of *x* and *y* through the training loop, and see how `W` and `b` evolve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "id": "GMXaQMpn2P3U"
   },
   "outputs": [],
   "source": [
    "model = MyModel()\n",
    "\n",
    "# Collect the history of W-values and b-values to plot later\n",
    "Ws, bs = [], []\n",
    "epochs = range(10)\n",
    "\n",
    "# Define a training loop\n",
    "def training_loop(model, x, y):\n",
    "\n",
    "  for epoch in epochs:\n",
    "    # Update the model with the single giant batch\n",
    "    train(model, x, y, learning_rate=0.1)\n",
    "\n",
    "    # Track this before I update\n",
    "    Ws.append(model.w.numpy())\n",
    "    bs.append(model.b.numpy())\n",
    "    current_loss = loss(y, model(x))\n",
    "\n",
    "    print(\"Epoch %2d: W=%1.2f b=%1.2f, loss=%2.5f\" %\n",
    "          (epoch, Ws[-1], bs[-1], current_loss))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 456
    },
    "id": "zHq-D4fI2P3U",
    "outputId": "5d7ca994-0171-44bc-87f6-a8f05ed59c9a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting: W=5.00 b=0.00, loss=8.51679\n",
      "Epoch  0: W=4.62 b=0.38, loss=5.86963\n",
      "Epoch  1: W=4.31 b=0.69, loss=4.15616\n",
      "Epoch  2: W=4.07 b=0.94, loss=3.04704\n",
      "Epoch  3: W=3.87 b=1.14, loss=2.32911\n",
      "Epoch  4: W=3.71 b=1.31, loss=1.86439\n",
      "Epoch  5: W=3.58 b=1.44, loss=1.56358\n",
      "Epoch  6: W=3.48 b=1.54, loss=1.36887\n",
      "Epoch  7: W=3.39 b=1.63, loss=1.24283\n",
      "Epoch  8: W=3.33 b=1.69, loss=1.16124\n",
      "Epoch  9: W=3.27 b=1.75, loss=1.10843\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Starting: W=%1.2f b=%1.2f, loss=%2.5f\" %\n",
    "      (model.w, model.b, loss(y, model(x))))\n",
    "\n",
    "# Do the training\n",
    "training_loop(model, x, y)\n",
    "\n",
    "# Plot it\n",
    "plt.plot(epochs, Ws, \"r\",\n",
    "         epochs, bs, \"b\")\n",
    "\n",
    "plt.plot([TRUE_W] * len(epochs), \"r--\",\n",
    "         [TRUE_B] * len(epochs), \"b--\")\n",
    "\n",
    "plt.legend([\"W\", \"b\", \"True W\", \"True b\"])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "id": "_YTFGttx2P3V",
    "outputId": "1b971431-690e-44c4-db1f-3f8d2d4c636c"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current loss: 1.108428\n"
     ]
    }
   ],
   "source": [
    "# Visualize how the trained model performs\n",
    "plt.scatter(x, y, c=\"b\")\n",
    "plt.scatter(x, model(x), c=\"r\")\n",
    "plt.show()\n",
    "\n",
    "print(\"Current loss: %1.6f\" % loss(model(x), y).numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7W-snCwT2P3V"
   },
   "source": [
    "## The same solution, but with Keras\n",
    "\n",
    "It's useful to contrast the code above with the equivalent in Keras.\n",
    "\n",
    "Defining the model looks exactly the same if you subclass `tf.keras.Model`.  Remember that Keras models inherit ultimately from module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q73Qkdua2P3W",
    "outputId": "6c2b3583-d0e9-44f6-bdca-02d12f68531e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  0: W=4.62 b=0.38, loss=5.86963\n",
      "Epoch  1: W=4.31 b=0.69, loss=4.15616\n",
      "Epoch  2: W=4.07 b=0.94, loss=3.04704\n",
      "Epoch  3: W=3.87 b=1.14, loss=2.32911\n",
      "Epoch  4: W=3.71 b=1.31, loss=1.86439\n",
      "Epoch  5: W=3.58 b=1.44, loss=1.56358\n",
      "Epoch  6: W=3.48 b=1.54, loss=1.36887\n",
      "Epoch  7: W=3.39 b=1.63, loss=1.24283\n",
      "Epoch  8: W=3.33 b=1.69, loss=1.16124\n",
      "Epoch  9: W=3.27 b=1.75, loss=1.10843\n"
     ]
    }
   ],
   "source": [
    "class MyModelKeras(tf.keras.Model):\n",
    "  def __init__(self, **kwargs):\n",
    "    super().__init__(**kwargs)\n",
    "    # Initialize the weights to `5.0` and the bias to `0.0`\n",
    "    # In practice, these should be randomly initialized\n",
    "    self.w = tf.Variable(5.0)\n",
    "    self.b = tf.Variable(0.0)\n",
    "\n",
    "  def call(self, x):\n",
    "    return self.w * x + self.b\n",
    "\n",
    "keras_model = MyModelKeras()\n",
    "\n",
    "# Reuse the training loop with a Keras model\n",
    "training_loop(keras_model, x, y)\n",
    "\n",
    "# You can also save a checkpoint using Keras's built-in support\n",
    "keras_model.save_weights(\"my_checkpoint\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yYbFhM7d2P3W"
   },
   "source": [
    "Rather than write new training loops each time you create a model, you can use the built-in features of Keras as a shortcut.  This can be useful when you do not want to write or debug Python training loops.\n",
    "\n",
    "If you do, you will need to use `model.compile()` to set the parameters, and `model.fit()` to train.  It can be less code to use Keras implementations of L2 loss and gradient descent, again as a shortcut.  Keras losses and optimizers can be used outside of these convenience functions, too, and the previous example could have used them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "id": "-Lu5Bzgh2P3X"
   },
   "outputs": [],
   "source": [
    "keras_model = MyModelKeras()\n",
    "\n",
    "# compile sets the training parameters\n",
    "keras_model.compile(\n",
    "    # By default, fit() uses tf.function().  You can\n",
    "    # turn that off for debugging, but it is on now.\n",
    "    run_eagerly=False,\n",
    "\n",
    "    # Using a built-in optimizer, configuring as an object\n",
    "    optimizer=tf.keras.optimizers.SGD(learning_rate=0.1),\n",
    "\n",
    "    # Keras comes with built-in MSE error\n",
    "    # However, you could use the loss function\n",
    "    # defined above\n",
    "    loss=tf.keras.losses.mean_squared_error,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UOmFPpqA2P3X"
   },
   "source": [
    "Keras `fit` expects batched data or a complete dataset as a NumPy array.  NumPy arrays are chopped into batches and default to a batch size of 32.\n",
    "\n",
    "In this case, to match the behavior of the hand-written loop, you should pass `x` in as a single batch of size 1000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sZyY5Jt32P3X",
    "outputId": "29d99e51-32ef-48f0-9605-d5033284de46"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 0s 386ms/step - loss: 8.5168\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 5.8696\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 4.1562\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.0470\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2.3291\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.8644\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.5636\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.3689\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.2428\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.1612\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa2bb8ca890>"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(x.shape[0])\n",
    "keras_model.fit(x, y, epochs=10, batch_size=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PVbpH8gB2P3Y"
   },
   "source": [
    "Note that Keras prints out the loss after training, not before, so the first loss appears lower, but otherwise this shows essentially the same training performance."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "1VOEHdMMleUC",
    "iO8Thjqak8Ky",
    "zvnhIloYk8lW",
    "7PN_2-Sq2P3K"
   ],
   "name": "intro-tf-demo-tfv2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
